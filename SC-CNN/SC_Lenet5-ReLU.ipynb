{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae42e62d-52d5-41e3-bb1a-0c7ba65c3ab7",
   "metadata": {},
   "source": [
    "# Module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "114df7ea-c3fa-47d7-bafc-9fe76df81d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50ca4e35-8d94-4b99-ad88-17bafe959f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.remove('/home/jungeun/.local/lib/python3.6/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03864434-da87-456a-93e6-62af0c563c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "705d78e1-ad89-467a-9790-a99e93d5e012",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/jungeun/.local/lib/python3.6/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73436471-c50a-448d-9823-7a87a58a0580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.2+cu113'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca16aa19-2854-4698-86d6-dafe0a396296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.9 (default, Mar 15 2022, 13:55:28) \\n[GCC 8.4.0]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af3dc806-0419-4fb4-b7b7-3e1b2b97a946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/usr/lib/python36.zip',\n",
       " '/usr/lib/python3.6',\n",
       " '/usr/lib/python3.6/lib-dynload',\n",
       " '',\n",
       " '/usr/local/lib/python3.6/dist-packages',\n",
       " '/usr/lib/python3/dist-packages',\n",
       " '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n",
       " '/home/jungeun/.ipython',\n",
       " '/home/jungeun/.local/lib/python3.6/site-packages']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd87a4ee-34c6-40c8-be95-b0bfa5f56e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from torchsummary import summary\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook as tq\n",
    "import os, time, math, copy,random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "#from torchvision import transforms, datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "torch.set_printoptions(precision=8, linewidth=50000)\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8648b97-144a-4c6d-951a-5cc9f8180055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/usr/lib/python36.zip',\n",
       " '/usr/lib/python3.6',\n",
       " '/usr/lib/python3.6/lib-dynload',\n",
       " '',\n",
       " '/usr/local/lib/python3.6/dist-packages',\n",
       " '/usr/lib/python3/dist-packages',\n",
       " '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n",
       " '/home/jungeun/.ipython',\n",
       " '/home/jungeun/.local/lib/python3.6/site-packages']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936610fc-b826-4105-b8f5-aca27e1f55cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Print Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84c80e2d-6adf-4fee-832d-ca9be8808d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACK\t= '\\033[30m'\n",
    "RED\t\t= '\\033[31m'\n",
    "GREEN\t= '\\033[32m'\n",
    "YELLOW\t= '\\033[33m'\n",
    "BLUE\t= '\\033[34m'\n",
    "MAGENTA\t= '\\033[35m'\n",
    "CYAN\t= '\\033[36m'\n",
    "RESET\t= '\\033[0m'\n",
    "SEL\t\t= '\\033[7m'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf66e7dd-b063-411f-80fa-280a45f832a8",
   "metadata": {},
   "source": [
    "# Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c48657bb-c1ff-4a62-b8f9-766f62bb3766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int2bin(iIn,iBW):\n",
    "    iBW = iBW + 1\n",
    "    if iIn >= 0:\n",
    "        bOut = bin(iIn).replace('0b','').rjust(iBW,'0')\n",
    "    else :\n",
    "        bOut = bin(iIn & (pow(2,iBW)-1)).replace('0b','').rjust(iBW,'1')\n",
    "    return bOut[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4b8aba6-c084-40c8-b0dd-7b71d979cf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XOR(iA,iB):\n",
    "    if iA != iB :\n",
    "        iOut = 1\n",
    "    else : \n",
    "        iOut = 0\n",
    "    return iOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11d4e43a-54cb-42e9-a760-5e0ce5a56732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def snum(a):\n",
    "    if a >= 0 :\n",
    "        return 0\n",
    "    else :\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e63dbabf-5b06-4907-a4cd-c21b68724191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binInv(bIn):\n",
    "    bOut = bin(int(bIn,2)^(pow(2,len(bIn))-1)).replace('0b','').rjust(len(bIn),'0')\n",
    "    return bOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6baaafc7-ecf6-486d-b873-a4871de46956",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LFSR7:\n",
    "    def Random(self):\n",
    "        self.b0 = eval(f'str(random.randint(0,1))')\n",
    "        self.b1 = eval(f'str(random.randint(0,1))')\n",
    "        self.b2 = eval(f'str(random.randint(0,1))')\n",
    "        self.b3 = eval(f'str(random.randint(0,1))')\n",
    "        self.b4 = eval(f'str(random.randint(0,1))')\n",
    "        self.b5 = eval(f'str(random.randint(0,1))')\n",
    "        self.b6 = eval(f'str(random.randint(0,1))')\n",
    "        if int(self.b0) + int(self.b1) + int(self.b2) + int(self.b3) + int(self.b4) + int(self.b5) + int(self.b6) == 0 :\n",
    "            self.b0 = eval(f'str(random.randint(0,1))')\n",
    "            self.b1 = eval(f'str(random.randint(0,1))')\n",
    "            self.b2 = eval(f'str(random.randint(0,1))')\n",
    "            self.b3 = eval(f'str(random.randint(0,1))')\n",
    "            self.b4 = eval(f'str(random.randint(0,1))')\n",
    "            self.b5 = eval(f'str(random.randint(0,1))')\n",
    "            self.b6 = eval(f'str(random.randint(0,1))')\n",
    "        return self.b0 + self.b1 + self.b2 + self.b3 + self.b4 + self.b5 + self.b6\n",
    "    \n",
    "    def Normal(self,stream):\n",
    "        self.b0 = str(XOR(int(stream[5]),int(stream[6])))\n",
    "        self.b1 = str(stream[0])\n",
    "        self.b2 = str(stream[1])\n",
    "        self.b3 = str(stream[2])\n",
    "        self.b4 = str(stream[3])\n",
    "        self.b5 = str(stream[4])\n",
    "        self.b6 = str(stream[5])\n",
    "        \n",
    "        return self.b0 + self.b1 + self.b2 + self.b3 + self.b4 + self.b5 + self.b6\n",
    "    \n",
    "    def Allzero(self):\n",
    "        self.b0 = '0'\n",
    "        self.b1 = '0'\n",
    "        self.b2 = '0'\n",
    "        self.b3 = '0'\n",
    "        self.b4 = '0'\n",
    "        self.b5 = '0'\n",
    "        self.b6 = '0'\n",
    "        \n",
    "        return self.b0 + self.b1 + self.b2 + self.b3 + self.b4 + self.b5 + self.b6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ce8c102-3374-4e00-9cfc-b46bd7402a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LFSRlist7():\n",
    "    lfsr = LFSR7()\n",
    "    lfsrlist = []\n",
    "    for k in range(2**(args.bBW)-1): #lfsr number generating\n",
    "        if k == 0:\n",
    "            lfsrlist.append(lfsr.Random())\n",
    "        else :\n",
    "            lfsrlist.append(lfsr.Normal(lfsrlist[k-1]))\n",
    "        if (k == 2**(args.bBW)-2):\n",
    "            lfsrlist.append(lfsr.Allzero())\n",
    "    \n",
    "    if (args.bBW) != args.frac_bits :\n",
    "        if args.bBW < args.frac_bits :\n",
    "            for i in range(len(lfsrlist)):\n",
    "                lfsrlist[i] = lfsrlist[i] + (args.frac_bits-args.bBW)*'0'\n",
    "        else :\n",
    "            print(\"it can't work\")\n",
    "            return 0\n",
    "    \n",
    "    return lfsrlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d8a0adf-8c1b-43bd-8f33-bfa1dae2fe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Comp(a,lfsr,snum): #lfsr number < origin number , output = 1\n",
    "    for com in range(0,len(a)):\n",
    "        oA = 0\n",
    "        if a[com]!=lfsr[com]:\n",
    "            if(int(a[com]) > int(lfsr[com])):\n",
    "                oA = 1\n",
    "            else :\n",
    "                oA = 0\n",
    "            break\n",
    "    return XOR(oA,snum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3775ec35-3207-4d6c-ae3d-8bee647a23e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perm(a):\n",
    "    al = len(a)\n",
    "    blist = []\n",
    "    if args.frac_bits == args.bBW : \n",
    "        for i in range(al) :\n",
    "            blist.append(a[al-i-1])\n",
    "    elif args.frac_bits > args.bBW :\n",
    "        for i in range(al-(args.frac_bits-args.bBW)) :\n",
    "            blist.append((a[al-(args.frac_bits-args.bBW)-i-1]))\n",
    "    b = \"\".join(blist)\n",
    "    b = b + ('0'*(args.frac_bits-args.bBW))\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78b1cbd0-9efe-47dc-b6bd-fbeec66583a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMaxMin(data):\n",
    "    max = torch.max(data)\n",
    "    min = torch.min(data)\n",
    "    SF=torch.max(abs(max),abs(min)).item()\n",
    "    return SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0eda18d7-8123-4fb2-8814-a0849d0ed141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CountOne(nIn):\n",
    "    nlist = []\n",
    "    for num in nIn.view(-1,nIn.size()[-1]):\n",
    "        n = 0\n",
    "        for a in num:\n",
    "            if a == 1 :\n",
    "                n += 1\n",
    "        if num[0] == 1 :\n",
    "            nlist.append(n-1)\n",
    "        else :\n",
    "            nlist.append(n)\n",
    "    return torch.tensor(nlist).view(nIn.size()[0],nIn.size()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d252b5cf-558f-4287-93a5-4f5b853df6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CountOne1(nIn):\n",
    "    n = 0\n",
    "    for num in nIn :\n",
    "        if num.item() == 1 :\n",
    "            n += 1\n",
    "    if nIn[0].item() == 1 :\n",
    "        n = n - 1\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d73ff905-c3f9-4fe7-a437-eaf0b94803c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def defSign(nIn):\n",
    "    nlist = []\n",
    "    k = nIn.view(-1,nIn.size()[-1])\n",
    "    for num in nIn.view(-1,nIn.size()[-1]):\n",
    "        if num[0] == 1 :\n",
    "            nlist.append(-1)\n",
    "        else :\n",
    "            nlist.append(1)\n",
    "    return torch.tensor(nlist).view(nIn.size()[0],nIn.size()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa609aef-da1e-4a38-8704-6420ea6ab7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def defSign1(nIn):\n",
    "    if nIn[0].item() == 1 :\n",
    "        return -1\n",
    "    else :\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4b980ef-68ca-4e7c-a9c9-c05b7696d274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SNG(iIN,lfsr):\n",
    "    if iIN == 1:\n",
    "        iIN = 0.9999\n",
    "    sNUM = snum(iIN)\n",
    "    \n",
    "    bIN = flp2fix(iIN,args.full_bits,args.frac_bits).bFull\n",
    "    bFRAC = bIN[-(args.frac_bits):]\n",
    "    oAlist = []\n",
    "    \n",
    "    for k in range(2**(args.bBW)): #lfsr number generating\n",
    "        lNUM = lfsr[k]\n",
    "        a = Comp(bFRAC,lNUM,sNUM)\n",
    "        oAlist.append(a) #comparator of input a\n",
    "    \n",
    "    oAlist.insert(0,sNUM)\n",
    "    #sA = \"\".join(oAlist)\n",
    "    if bIN == args.full_bits*'0' :\n",
    "        return torch.zeros((2**args.bBW)+1)\n",
    "    else :\n",
    "        return torch.tensor(oAlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43990971-acf3-49c1-b09f-5691f491872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SNGtensor(fIn,lfsr):\n",
    "    sList = []\n",
    "    fsize = list(fIn.size())\n",
    "    fsize.insert(2,(2**args.bBW)+1)\n",
    "    for aTensor in fIn.view(-1):\n",
    "        sList.append(SNG(aTensor,lfsr))\n",
    "    \n",
    "    c = torch.stack(sList,0)\n",
    "    return c.view(fsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16679751-d2e4-485b-af10-9c473e40e79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SNG_P(iIN,lfsr):\n",
    "    if iIN == 1:\n",
    "        iIN = 0.9999\n",
    "    sNUM = snum(iIN)\n",
    "    \n",
    "    bIN = flp2fix(iIN,args.full_bits,args.frac_bits).bFull\n",
    "    bFRAC = bIN[-(args.frac_bits):]\n",
    "    oAlist = []\n",
    "    \n",
    "    for k in range(2**(args.bBW)): #lfsr number generating\n",
    "        lNUM = perm(lfsr[k])\n",
    "        a = Comp(bFRAC,lNUM,sNUM)\n",
    "        oAlist.append(a) #comparator of input a\n",
    "    \n",
    "    oAlist.insert(0,sNUM)\n",
    "    #sA = \"\".join(oAlist)\n",
    "    if bIN == args.full_bits*'0' :\n",
    "        return torch.zeros((2**args.bBW)+1)\n",
    "    else :\n",
    "        return torch.tensor(oAlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d28f528-e012-4f00-af38-5be2bb0a6e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SNGPtensor(fIn,lfsr):\n",
    "    sList = []\n",
    "    fsize = list(fIn.size())\n",
    "    fsize.insert(2,(2**args.bBW)+1)\n",
    "    for aTensor in fIn.view(-1):\n",
    "        sList.append(SNG_P(aTensor,lfsr))\n",
    "    \n",
    "    c = torch.stack(sList,0)\n",
    "    return c.view(fsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90469535-f7d3-4286-baf4-3886e161a41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mul(a,b):\n",
    "    outlist = []\n",
    "    \n",
    "    if len(a) != len(b) :\n",
    "        print(\"length of string is different\")\n",
    "        return 0\n",
    "    \n",
    "    outlist.append(XOR(a[0],b[0]))\n",
    "    \n",
    "    for anum,bnum in zip(a[1:],b[1:]) :\n",
    "        try :\n",
    "            outlist.append(int(anum)&int(bnum))\n",
    "        except RuntimeError :\n",
    "            print(anum.type())\n",
    "            print(bnum.type())\n",
    "            \n",
    "    o = torch.tensor(outlist)\n",
    "    return o "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c2a40ea-cdd5-4681-9e03-9d79acfd2475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Multensor(aIn,wIn):\n",
    "    olist = []\n",
    "    for a,w in zip(aIn.view(-1,aIn.size()[-1]),wIn.view(-1,wIn.size()[-1])):\n",
    "        o = mul(a,w)\n",
    "        olist.append(o)\n",
    "    out = torch.stack(olist,0)\n",
    "    return out.view(aIn.size()[0],wIn.size()[1],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ecc61d9a-ff48-4c1d-9cb4-6f7408d0b793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convert(sIn,SF):\n",
    "    s = defSign(sIn)\n",
    "    o = (CountOne(sIn)/(2**args.bBW))*SF*s\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23cb5132-cdf8-4e59-ad8c-7af47850de4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SCmulTensor(aIn,wIn,aSF,wSF):\n",
    "    a = aIn/aSF\n",
    "    w = wIn/wSF\n",
    "    \n",
    "    lfsr = LFSRlist7()\n",
    "    \n",
    "    Sa = SNGtensor(a,lfsr)\n",
    "    Sw = SNGPtensor(w,lfsr)\n",
    "    \n",
    "    Smul = Multensor(Sa,Sw)\n",
    "    \n",
    "    Bout = Convert(Smul,aSF*wSF)\n",
    "    \n",
    "    return Bout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b386dd23-5828-4ec9-bf59-61714fd92a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def StoConv(X, filters, bias, stride=1, pad=0):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    n, c, h, w = X.shape # 1, 1, 32, 32\n",
    "    n_f, _, filter_h, filter_w = filters.shape\n",
    "\n",
    "    out_h = (h+2*pad-filter_h)//stride + 1\n",
    "    out_w = (w+2*pad-filter_w)//stride + 1\n",
    "    # add padding to height and width.\n",
    "    in_X = F.pad(X,(0,0,0,0,pad,pad,pad,pad),\"constant\", 0)\n",
    "    out  = torch.zeros((n, n_f, out_h, out_w))\n",
    "    \n",
    "    for i in range(n): # for each image.\n",
    "        aSF = findMaxMin(in_X[i])\n",
    "        for c in range(n_f): # for each channel.\n",
    "            wSF = findMaxMin(filters[c])\n",
    "            for h in range(out_h): # slide the filter vertically.\n",
    "                h_start = h * stride\n",
    "                h_end = h_start + filter_h\n",
    "                for w in range(out_w): # slide the filter horizontally.\n",
    "                    w_start = w * stride\n",
    "                    w_end = w_start + filter_w\n",
    "                    # Element-wise multiplication.\n",
    "                    out[i, c, h, w] = torch.sum(SCmulTensor(in_X[i,:,h_start:h_end,w_start:w_end],filters[c],aSF,wSF)) + bias[c]\n",
    "                    \n",
    "    end = time.time()\n",
    "    sec = (end-start)\n",
    "    result_list = str(datetime.timedelta(seconds=sec)).split(\".\")\n",
    "    print(f'Total time is : {result_list[0]}')\n",
    "    \n",
    "    return out.to(args.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7ff7d8-6cd4-4632-9b8b-26a489db5368",
   "metadata": {},
   "source": [
    "# fixed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b818caed-4260-48a0-924f-5e416ba01516",
   "metadata": {},
   "outputs": [],
   "source": [
    "class\tfxp:\n",
    "\tdef\t__init__(self, bIn, iBWF):\n",
    "\t\tself.iFullBW\t= len(bIn)\n",
    "\t\tself.iIntgBW\t= self.iFullBW - iBWF\n",
    "\t\tself.bSign\t\t= bIn[0]\n",
    "\t\tself.bIntg\t\t= bIn[:self.iIntgBW]\n",
    "\t\tself.bFrac\t\t= bIn[self.iIntgBW:]\n",
    "\t\tself.fFull\t\t= 0\n",
    "\t\ttry:\n",
    "\t\t\tfor idx, bit in enumerate(bIn):\n",
    "\t\t\t\tif\tidx == 0:\n",
    "\t\t\t\t\tself.fFull = self.fFull + int(bit,2) * -pow(2, self.iIntgBW - 1)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tself.fFull = self.fFull + int(bit,2) * pow(2, self.iIntgBW - 1 - idx)\n",
    "\t\texcept:\n",
    "\t\t\tprint(bIn)\n",
    "\t\tself.dispFull\t= RED + self.bIntg + BLUE + self.bFrac + RESET\n",
    "\t\treturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2e331f5-009b-4790-b614-15dc7144f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "class flp2fix:\n",
    "    def __init__(self, fIn, iBW, iBWF):\n",
    "        self.fMin = - 2 ** (iBW - iBWF - 1)\n",
    "        self.fMax = (2 ** (iBW-1) - 1) * (2 ** -iBWF)\n",
    "        self.fResol = 2 ** -iBWF\n",
    "        #if fIn < self.fMin or fIn > self.fMax:\n",
    "            #print(f'({fIn}): Out of input range ({self.fMax}/{self.fMin}) during flp -> fix converting ')\n",
    "        self.iBW = iBW\n",
    "        self.iBWI = iBW - iBWF\n",
    "        self.iBWF = iBWF\n",
    "\n",
    "        self.iFLP2INT = abs(int(fIn * 2 ** iBWF))\n",
    "        if fIn < 0:\n",
    "            self.iFLP2INT = 2 ** (iBW-1) - self.iFLP2INT\n",
    "\n",
    "        if fIn >= 0:\n",
    "            self.bFull = bin(self.iFLP2INT)[2:].rjust(iBW, '0')\n",
    "        else:\n",
    "            self.bFull = '1'+bin(self.iFLP2INT)[2:].rjust(iBW-1, '0')\n",
    "            if len(self.bFull) > iBW:\n",
    "                self.bFull = '0' * iBW\n",
    "\n",
    "        self.cssFxp = fxp(self.bFull, self.iBWF)\n",
    "        self.bSign = self.cssFxp.bSign\n",
    "        self.bIntg = self.cssFxp.bIntg\n",
    "        self.bFrac = self.cssFxp.bFrac\n",
    "        self.fFull = self.cssFxp.fFull\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57220a95-6aae-4dfc-a4d4-03f0900bd16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def\tflp2fixTensor(fIn, iBW, iBWF):\n",
    "\tfMin = - 2 ** (iBW - iBWF - 1)\n",
    "\tfMax = (2 ** (iBW-1) - 1) * (2 ** -iBWF)\n",
    "\tfList = []\n",
    "\tfor aTensor in fIn.view(-1):\n",
    "\t\tfList.append(flp2fix(aTensor, iBW, iBWF).fFull)\n",
    "\treturn torch.tensor(fList).view(fIn.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cbb61a-5058-4370-8b41-7ad6f40821a0",
   "metadata": {},
   "source": [
    "# User Define Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7d796ed-a96c-4502-a51d-3e3338d2e852",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '~/dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44ec692-3652-432b-892e-3726275b1d33",
   "metadata": {},
   "source": [
    "# Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6523c2a6-2b6a-4b17-826c-0485fed12da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch for MNIST dataset')\n",
    "parser.add_argument('--device', type=str, default='cpu', help='Device')\n",
    "parser.add_argument('--shuffle', action='store_true', default=False, help='enables data shuffle')\n",
    "parser.add_argument('--dataset', type=str, default='mnist', help='training dataset')\n",
    "parser.add_argument('--data_path', type=str, default=data_path, help='path to MNIST')\n",
    "parser.add_argument('--batch_size', type=int, default=64, help='batch size')\n",
    "parser.add_argument('--epochs', type=int, default=30, help='number of epochs to train')\n",
    "parser.add_argument('--lr', type=float, default=0.001, help='learning rate')\n",
    "parser.add_argument('--optimizer', type=str, default='adam', help='optimizer')\n",
    "parser.add_argument('--loss_func', type=str, default='cel', help='optimizer')\n",
    "parser.add_argument('--quant_opt', type=str, default='asym', help='Type of Quantization')\n",
    "parser.add_argument('--full_bits', type=int, default=16, help='Number of Quantization Bits')\n",
    "parser.add_argument('--frac_bits', type=int, default=8, help='Number of Quantization Bits')\n",
    "parser.add_argument('--pretrained', type=bool, default=True, help='Pretrained Model')\n",
    "parser.add_argument('--act_quant', type=bool, default=False, help='Activation Quantization')\n",
    "parser.add_argument('--disp', type=bool, default=False, help='Display Model Information')\n",
    "parser.add_argument('--bBW',type=int,default=7,help='bit number')\n",
    "args = parser.parse_args(args=[])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198fe2c8-a1dc-4186-8dae-e8e5393751d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "38f1d7e8-ce95-4537-9b87-4178ebbd71cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args.device == 'cuda' else {}\n",
    "tr = transforms.Compose([transforms.Resize((32,32)),transforms.ToTensor()])\n",
    "if args.dataset == 'mnist':\n",
    "\ttrain_loader = torch.utils.data.DataLoader(\n",
    "\t\tdataset=datasets.MNIST(\n",
    "\t\t\troot=args.data_path,\n",
    "\t\t\ttrain=True,\n",
    "\t\t\tdownload=True,\n",
    "\t\t\ttransform=tr\n",
    "\t\t),\n",
    "\t\tbatch_size=args.batch_size,\n",
    "\t\tshuffle=args.shuffle,\n",
    "\t\t**kwargs\n",
    "\t)\n",
    "\n",
    "\ttest_loader = torch.utils.data.DataLoader(\n",
    "\t\tdataset=datasets.MNIST(\n",
    "\t\t\troot=args.data_path,\n",
    "\t\t\ttrain=False,\n",
    "\t\t\tdownload=True,\n",
    "\t\t\ttransform=tr\n",
    "\t\t),\n",
    "\t\tbatch_size=args.batch_size,\n",
    "\t\tshuffle=args.shuffle,\n",
    "\t\t**kwargs\n",
    "\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d02fd0-7e51-4fa1-8c9c-43f315ed2e45",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e513158-8790-4a04-8e2e-f0396b6c4f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lenet5(nn.Module):\n",
    "    def __init__(self): #layer sequential define\n",
    "        super(Lenet5, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5*5 square convolution\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.Conv2d1 = nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = 5, stride = 1)\n",
    "        self.Conv2d2 = nn.Conv2d(in_channels = 6, out_channels = 16, kernel_size = 5, stride = 1)\n",
    "        self.Conv2d3 = nn.Conv2d(in_channels = 16, out_channels = 120, kernel_size = 5, stride = 1)\n",
    "        self.AvgPool2d = nn.AvgPool2d(kernel_size = 2)\n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.Linear1 = nn.Linear(120, 84)\n",
    "        self.Linear2 = nn.Linear(84, 10)\n",
    "    def forward(self, x) :\n",
    "        x = self.Conv2d1(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.AvgPool2d(x)\n",
    "        x = self.Conv2d2(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.AvgPool2d(x)\n",
    "        x = self.Conv2d3(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.Linear1(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.Linear2(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2954b3fb-7b41-447f-9704-814b56fe39ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genOptimizer(model, args):\n",
    "\tif args.optimizer == 'sgd':\n",
    "\t\toptimizer = torch.optim.SGD(model.parameters(), lr=args.lr)\n",
    "\tif args.optimizer == 'adam':\n",
    "\t\toptimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\treturn optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b5ff14c3-1b18-4039-9bd7-41a89b1e7853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genLossFunc(args):\n",
    "\tif args.loss_func == 'cel':\n",
    "\t\tloss_func = nn.CrossEntropyLoss()\n",
    "\treturn loss_func.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "947280a4-c6f5-46dd-be01-a8a253e9f107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, epoch, args):\n",
    "    model.train()\n",
    "    loss_func = genLossFunc(args)\n",
    "    optimizer = genOptimizer(model, args)\n",
    "    max_batch_index = int(np.floor(len(train_loader.dataset)/args.batch_size)) #batch 번호 ..?\n",
    "    running_loss,correct = 0, 0\n",
    "    \n",
    "    for batch_index, (image, label) in enumerate(tq(train_loader, desc='Train', leave=False)):\n",
    "        image, label = image.to(args.device), label.to(args.device)\n",
    "        pred = model(image) #pred = model\n",
    "        loss = loss_func(pred, label) # model 이용해서 loss 구함)\n",
    "        running_loss += loss.item()#*image.size(0)\n",
    "        correct += (pred.argmax(1) == label).type(torch.int).sum().item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    final_loss = running_loss/len(train_loader.dataset)\n",
    "    correct_rate = 100 * correct / len(train_loader.dataset)\n",
    "    print(f'Epoch {epoch+1:<3d}: Avg. Loss: {final_loss:.4f}', end = '\\t')\n",
    "    print(f'Accuracy: {correct}/{len(train_loader.dataset)} ({correct_rate:>.1f}%)')\n",
    "    \n",
    "    return final_loss,correct_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7912a90e-f739-4ccb-94f1-12f0557e2768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model, args):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loss_func = genLossFunc(args)\n",
    "        loss, correct = 0, 0\n",
    "# for batch_index, (image, label) in enumerate(tq(test_loader, desc='Test', leave=False)):\n",
    "        for batch_index, (image, label) in enumerate(test_loader):\n",
    "            image, label = image.to(args.device), label.to(args.device)\n",
    "            pred = model(image)\n",
    "            loss += loss_func(pred, label).item()#*image.size(0)\n",
    "            correct += (pred.argmax(1) == label).type(torch.int).sum().item()\n",
    "    loss /= len(test_loader.dataset)\n",
    "    correct_rate = 100 * correct / len(test_loader.dataset)\n",
    "    print(f'Accuracy: {correct}/{len(test_loader.dataset)} ({correct_rate:>.1f}%)')\n",
    "    return loss,correct_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40cceb3b-abd3-49ae-a11a-f88cfe68790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model):\n",
    "    train_loss_hist = []\n",
    "    train_acc_hist = []\n",
    "    eval_loss_hist = []\n",
    "    eval_acc_hist = []\n",
    "    for epoch in range(args.epochs):\n",
    "        train_loss,train_acc = train(train_loader, model, epoch, args)\n",
    "        eval_loss,eval_acc = test(test_loader, model, args)\n",
    "        train_loss_hist.append(train_loss)\n",
    "        eval_loss_hist.append(eval_loss)\n",
    "        train_acc_hist.append(train_acc)\n",
    "        eval_acc_hist.append(eval_acc)\n",
    "    print(\"Done!\")\n",
    "    return model,train_loss_hist,train_acc_hist,eval_loss_hist,eval_acc_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fde61a62-638f-4d26-9dec-ff44b437702e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1  : Avg. Loss: 0.0053\tAccuracy: 53713/60000 (89.5%)\n",
      "Accuracy: 9596/10000 (96.0%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2  : Avg. Loss: 0.0015\tAccuracy: 58233/60000 (97.1%)\n",
      "Accuracy: 9715/10000 (97.2%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3  : Avg. Loss: 0.0010\tAccuracy: 58810/60000 (98.0%)\n",
      "Accuracy: 9802/10000 (98.0%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4  : Avg. Loss: 0.0007\tAccuracy: 59159/60000 (98.6%)\n",
      "Accuracy: 9844/10000 (98.4%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5  : Avg. Loss: 0.0006\tAccuracy: 59337/60000 (98.9%)\n",
      "Accuracy: 9864/10000 (98.6%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6  : Avg. Loss: 0.0005\tAccuracy: 59469/60000 (99.1%)\n",
      "Accuracy: 9859/10000 (98.6%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7  : Avg. Loss: 0.0004\tAccuracy: 59536/60000 (99.2%)\n",
      "Accuracy: 9861/10000 (98.6%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8  : Avg. Loss: 0.0003\tAccuracy: 59598/60000 (99.3%)\n",
      "Accuracy: 9856/10000 (98.6%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9  : Avg. Loss: 0.0003\tAccuracy: 59662/60000 (99.4%)\n",
      "Accuracy: 9869/10000 (98.7%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 : Avg. Loss: 0.0003\tAccuracy: 59697/60000 (99.5%)\n",
      "Accuracy: 9861/10000 (98.6%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 : Avg. Loss: 0.0002\tAccuracy: 59705/60000 (99.5%)\n",
      "Accuracy: 9867/10000 (98.7%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 : Avg. Loss: 0.0002\tAccuracy: 59738/60000 (99.6%)\n",
      "Accuracy: 9874/10000 (98.7%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 : Avg. Loss: 0.0002\tAccuracy: 59738/60000 (99.6%)\n",
      "Accuracy: 9867/10000 (98.7%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 : Avg. Loss: 0.0002\tAccuracy: 59769/60000 (99.6%)\n",
      "Accuracy: 9864/10000 (98.6%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 : Avg. Loss: 0.0002\tAccuracy: 59772/60000 (99.6%)\n",
      "Accuracy: 9879/10000 (98.8%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 : Avg. Loss: 0.0001\tAccuracy: 59821/60000 (99.7%)\n",
      "Accuracy: 9850/10000 (98.5%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 : Avg. Loss: 0.0002\tAccuracy: 59812/60000 (99.7%)\n",
      "Accuracy: 9879/10000 (98.8%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 : Avg. Loss: 0.0001\tAccuracy: 59845/60000 (99.7%)\n",
      "Accuracy: 9889/10000 (98.9%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 : Avg. Loss: 0.0001\tAccuracy: 59838/60000 (99.7%)\n",
      "Accuracy: 9892/10000 (98.9%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 : Avg. Loss: 0.0001\tAccuracy: 59839/60000 (99.7%)\n",
      "Accuracy: 9880/10000 (98.8%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 : Avg. Loss: 0.0001\tAccuracy: 59838/60000 (99.7%)\n",
      "Accuracy: 9892/10000 (98.9%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 : Avg. Loss: 0.0001\tAccuracy: 59861/60000 (99.8%)\n",
      "Accuracy: 9891/10000 (98.9%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 : Avg. Loss: 0.0001\tAccuracy: 59868/60000 (99.8%)\n",
      "Accuracy: 9896/10000 (99.0%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 : Avg. Loss: 0.0001\tAccuracy: 59862/60000 (99.8%)\n",
      "Accuracy: 9887/10000 (98.9%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 : Avg. Loss: 0.0001\tAccuracy: 59863/60000 (99.8%)\n",
      "Accuracy: 9880/10000 (98.8%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 : Avg. Loss: 0.0001\tAccuracy: 59865/60000 (99.8%)\n",
      "Accuracy: 9884/10000 (98.8%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 : Avg. Loss: 0.0001\tAccuracy: 59874/60000 (99.8%)\n",
      "Accuracy: 9882/10000 (98.8%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 : Avg. Loss: 0.0001\tAccuracy: 59872/60000 (99.8%)\n",
      "Accuracy: 9890/10000 (98.9%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 : Avg. Loss: 0.0001\tAccuracy: 59899/60000 (99.8%)\n",
      "Accuracy: 9887/10000 (98.9%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 : Avg. Loss: 0.0001\tAccuracy: 59887/60000 (99.8%)\n",
      "Accuracy: 9886/10000 (98.9%)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model,train_loss_hist,train_acc_hist,eval_loss_hist,eval_acc_hist = main(Lenet5().to(args.device))\n",
    "torch.save(model.state_dict(), 'PTQ.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "857f1ee9-62ad-4578-9240-14b9cef583f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenet5(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (Conv2d1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (Conv2d2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (Conv2d3): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (AvgPool2d): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (ReLU): ReLU()\n",
      "  (Linear1): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (Linear2): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "56c32ea6-b56b-4366-b66a-0180386cdb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2fix(model, args):\n",
    "\tfor name, _ in model.named_parameters():\n",
    "\t\texec(f'model.{name}.data = flp2fixTensor(model.{name}.data, {args.full_bits}, {args.frac_bits})')\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eb0dc285-7b7a-478c-8480-f799eb776ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantFixForward(model, x, args):\n",
    "    cmodel = copy.deepcopy(model).to(args.device)\n",
    "    with torch.no_grad():\n",
    "        x = flp2fixTensor(x,args.full_bits,args.frac_bits)\n",
    "        \n",
    "        print(\"input is gone\")\n",
    "        \n",
    "        cnv0 = StoConv(x,cmodel.Conv2d1.weight,cmodel.Conv2d1.bias, stride=1, pad=0).to(args.device)\n",
    "        cnv0 = flp2fixTensor(cnv0,args.full_bits,args.frac_bits)\n",
    "        \n",
    "        print(\"conv1 is done\")\n",
    "        \n",
    "        act0 = cmodel.ReLU(cnv0).to(args.device)\n",
    "        act0 = flp2fixTensor(act0, args.full_bits,args.frac_bits)\n",
    "        \n",
    "        avg0 = cmodel.AvgPool2d(act0).to(args.device) #activation\n",
    "        avg0 = flp2fixTensor(avg0, args.full_bits, args.frac_bits)\n",
    "\n",
    "        cnv1 = StoConv(avg0,cmodel.Conv2d2.weight,cmodel.Conv2d2.bias, stride=1, pad=0).to(args.device)\n",
    "        cnv1 = flp2fixTensor(cnv1, args.full_bits, args.frac_bits)\n",
    "        \n",
    "        print(\"conv2 is done\")\n",
    "        \n",
    "        act1 = cmodel.ReLU(cnv1).to(args.device)\n",
    "        act1 = flp2fixTensor(act1, args.full_bits, args.frac_bits)\n",
    "        \n",
    "        avg1 = cmodel.AvgPool2d(act1).to(args.device)\n",
    "        avg1 = flp2fixTensor(avg1, args.full_bits, args.frac_bits)\n",
    "        \n",
    "        cnv2 = StoConv(avg1,cmodel.Conv2d3.weight,cmodel.Conv2d3.bias, stride=1, pad=0).to(args.device)\n",
    "        cnv2 = flp2fixTensor(cnv2,args.full_bits,args.frac_bits)\n",
    "        \n",
    "        print(\"conv3 is done\")\n",
    "        \n",
    "        act2 = cmodel.ReLU(cnv2).to(args.device)\n",
    "        act2 = flp2fixTensor(act2, args.full_bits, args.frac_bits)\n",
    "            \n",
    "        flat = cmodel.flatten(act2).to(args.device)\n",
    "        flat = flp2fixTensor(flat,args.full_bits, args.frac_bits)\n",
    "        \n",
    "        fc1  = cmodel.Linear1(flat).to(args.device)\n",
    "        fc1  = flp2fixTensor(fc1, args.full_bits, args.frac_bits)\n",
    "        \n",
    "        act3 = cmodel.ReLU(fc1).to(args.device)\n",
    "        act3 = flp2fixTensor(act3,args.full_bits, args.frac_bits)\n",
    "        \n",
    "        fc2  = cmodel.Linear2(act3).to(args.device)\n",
    "        fc2  = flp2fixTensor(fc2, args.full_bits, args.frac_bits)\n",
    "        \n",
    "        act4 = cmodel.ReLU(fc2).to(args.device)\n",
    "        act4 = flp2fixTensor(fc2, args.full_bits, args.frac_bits)\n",
    "\n",
    "    return cmodel, cnv0, act0, avg0, cnv1, act1, avg1, cnv2, act2, flat, fc1, act3, fc2, act4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "99e36d99-176d-4efe-a6f3-65d0fe40c9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testQuant(model, test_loader,args):\n",
    "    qmodel = copy.deepcopy(model).to(args.device)\n",
    "    qmodel = model2fix(qmodel, args)\n",
    "    qmodel.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loss_func = genLossFunc(args)\n",
    "        loss, correct = 0, 0\n",
    "        for batch_index, (image, label) in enumerate(tq(test_loader,desc='Train', leave=False)):\n",
    "            image, label = image.to(args.device), label.to(args.device)\n",
    "            qmodel, cnv0, act0, avg0, cnv1, act1, avg1, cnv2, act2, flat, fc1, act3, fc2, act4  = quantFixForward(qmodel, image, args)\n",
    "            y = act4\n",
    "            loss += loss_func(y, label).item()#*image.size(0)\n",
    "            correct += (y.argmax(1) == label).type(torch.int).sum().item()\n",
    "    correct_rate = 100 * correct / len(test_loader.dataset)\n",
    "    print(f'Accuracy: {correct}/{len(test_loader.dataset)} ({correct_rate:>.1f}%) Loss: {loss/len(test_loader.dataset):.2f}')\n",
    "    return qmodel, cnv0.to(args.device), act0.to(args.device), avg0.to(args.device), cnv1.to(args.device), act1.to(args.device), avg1.to(args.device), cnv2.to(args.device), act2.to(args.device), flat.to(args.device), fc1.to(args.device), act3.to(args.device), fc2.to(args.device), act4.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0581e3bf-bcf5-481c-ab36-741eb030f29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a326458d7c4869b33d4d37441f1a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input is gone\n"
     ]
    }
   ],
   "source": [
    "qmodel, cnv0, act0, avg0, cnv1, act1, avg1, cnv2, act2, flat, fc1, act3, fc2, act4= testQuant(model,test_loader,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40474ba-f42a-46a0-b1dc-bad9d047d7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"eval-loss\")\n",
    "\n",
    "plt.plot(range(1,args.epochs+1),train_loss_hist,label=\"train\")\n",
    "plt.plot(range(1,args.epochs+1),eval_loss_hist,label=\"eval\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff57daf-f208-478c-9081-211ab6cf3d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Accuracy\")\n",
    "\n",
    "plt.plot(range(1,args.epochs+1),train_acc_hist,label=\"train\")\n",
    "plt.plot(range(1,args.epochs+1),eval_acc_hist,label=\"eval\")\n",
    "plt.ylabel(\"accruacy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee43b4ec-c7af-48cf-8d1c-4c03a14f0949",
   "metadata": {},
   "source": [
    "# Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2afdc0c-7bb9-42f4-a23b-e0faf6cce086",
   "metadata": {},
   "source": [
    "### conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4569ce2a-873f-4c72-af87-509498c7c40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(X, filters,bias, stride=1, pad=0):\n",
    "    n, c, h, w = X.shape # 1, 1, 32, 32\n",
    "    n_f, _, filter_h, filter_w = filters.shape\n",
    "    \n",
    "    out_h = (h+2*pad-filter_h)//stride + 1\n",
    "    out_w = (w+2*pad-filter_w)//stride + 1\n",
    "    # add padding to height and width.\n",
    "    in_X = F.pad(X,(0,0,0,0,pad,pad,pad,pad),\"constant\", 0)\n",
    "    out  = torch.zeros((n, n_f, out_h, out_w))\n",
    "    \n",
    "    for i in range(n): # for each image.\n",
    "        for c in range(n_f): # for each channel.\n",
    "            for h in range(out_h): # slide the filter vertically.\n",
    "                h_start = h * stride\n",
    "                h_end = h_start + filter_h\n",
    "                for w in range(out_w): # slide the filter horizontally.\n",
    "                    w_start = w * stride\n",
    "                    w_end = w_start + filter_w\n",
    "                    # Element-wise multiplication.\n",
    "                    out[i, c, h, w] = torch.sum(in_X[i,:,h_start:h_end,w_start:w_end]*filters[c])+bias[c]\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d097de5-3122-4451-a29e-9ecd2b8e30eb",
   "metadata": {},
   "source": [
    "### ReLU_4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee8d591-bbf5-4fcf-b206-bb8308e84983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU_4D(X):\n",
    "    n, c, h, w = X.shape\n",
    "    \n",
    "    out = torch.zeros(n,c,h,w)\n",
    "    \n",
    "    for i in range(n): #for each image\n",
    "        for ch in range(c) : #for each channel\n",
    "            for o_h in range(h) : #for each height\n",
    "                for o_w in range(w) : #for each width\n",
    "                    x = X[i, ch, o_h, o_w]\n",
    "                    if x > 0 :\n",
    "                        out[i, ch, o_h, o_w] = x\n",
    "                    else :\n",
    "                        out[i, ch, o_h, o_w] = 0\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b634285a-385c-4adc-b16d-48390b197cfd",
   "metadata": {},
   "source": [
    "### ReLU_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef2a00e-c5ad-426d-b421-dbb892fec801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU_2D(X):\n",
    "    n, c = X.shape\n",
    "    \n",
    "    out = torch.zeros(n,c)\n",
    "    \n",
    "    for i in range(n): #for each image\n",
    "        for ch in range(c) : #for each channel\n",
    "                    x = X[i, ch]\n",
    "                    if x > 0 :\n",
    "                        out[i, ch ] = x\n",
    "                    else :\n",
    "                        out[i, ch ] = 0\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b514de-2220-4e48-8c38-7eee5d2eba6f",
   "metadata": {},
   "source": [
    "### avgpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4628c8-42b1-4dcb-838d-20ed940f4307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def avgpool2d(X,kernel_size,stride,pad=0):\n",
    "    n, c, h, w = X.shape\n",
    "    ker_w, ker_h = kernel_size\n",
    "    \n",
    "    out_h = (h + 2*pad - ker_h)//stride + 1\n",
    "    out_w = (w + 2*pad - ker_w)//stride + 1\n",
    "    \n",
    "    out = torch.zeros(n,c,out_h,out_w)\n",
    "    for i in range(n) : #for each image\n",
    "        for ch in range(c) : #for each channel \n",
    "             for h in range(out_h) :\n",
    "                    h_start = h * stride\n",
    "                    h_end = h_start + ker_w\n",
    "                    for w in range(out_w):\n",
    "                        w_start = w * stride\n",
    "                        w_end = w_start + ker_w\n",
    "                        #element average\n",
    "                        out[i, ch, h, w] = torch.mean(X[i,ch,h_start:h_end,w_start:w_end])\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6f5e21-3675-4a78-9f94-4fbf4e1013a3",
   "metadata": {},
   "source": [
    "### linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7f176c-8735-4dcb-a763-6e685d280851",
   "metadata": {},
   "source": [
    "## checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa2d71b-b6d4-466e-b840-a598f7a57742",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters1 = qmodel.Conv2d1.weight\n",
    "filters2 = qmodel.Conv2d2.weight\n",
    "filters3 = qmodel.Conv2d3.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64c31c2-594e-4b57-b11a-704e9deec26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filters1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecbe49f-47f5-44d8-a408-df727d92c7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias1 = qmodel.Conv2d1.bias\n",
    "bias2 = qmodel.Conv2d2.bias\n",
    "bias3 = qmodel.Conv2d3.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84792791-321a-4fc9-931e-59a8d156c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_filter1 = qmodel.Linear1.weight\n",
    "linear_filter2 = qmodel.Linear2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f048caa-5905-4324-9d06-f8056b5806c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_bias1 = qmodel.Linear1.bias\n",
    "linear_bias2 = qmodel.Linear2.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6a0c8e-c3a2-430a-8311-d18c1877101c",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_filter1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dd94e7-f94e-4821-b7e7-a54144b5161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_filter2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23e07e1-d32a-49cf-9c7d-a65d4e66c61e",
   "metadata": {},
   "source": [
    "### act0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd151a5c-362d-4b25-8af9-0fe4d1ec9db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_conv1 = conv(flp2fixTensor(a_input,args.full_bits,args.frac_bits),filters1,bias1,stride=1,pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb262ca-a1f5-4539-b0dc-e5362b34b4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_ReLU1 = ReLU_4D(layer_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aca4a62-febd-4d03-b1d3-2c6db27fc94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_avgpool1 = avgpool2d(layer_ReLU1,(2,2),2,pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9274cd8-39f2-46e4-bb16-0d8abc208992",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_avgpool1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b4e9e4-b3ed-42b3-8775-bfd6cadbcc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "act0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6f87ac-43ba-48e0-8e76-077b7743b822",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_cnv0 = torch.zeros(16,6,28,28)\n",
    "\n",
    "total = 0\n",
    "num = 0\n",
    "\n",
    "for a in range(16) :\n",
    "    for b in range(6) :\n",
    "        for c in range(28) :\n",
    "            for d in range(28) :\n",
    "                fix_cnv0[a][b][c][d] = flp2fix(layer_conv1[a][b][c][d],args.full_bits,args.frac_bits).fFull\n",
    "                if (torch.equal(fix_cnv0[a][b][c][d],cnv0[a][b][c][d])==False):\n",
    "                    num += 1\n",
    "                #bin_conv1[a][b][c][d] = flp2fix(fix_conv1[a][b][c][d],args.full_bits,args.frac_bits).bFull\n",
    "                total += 1\n",
    "\n",
    "print(\"number of different value is : {num}/{total}\".format(num=num,total=total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48be63e-b475-43a3-96c8-1b47ab42a723",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(fix_cnv0,cnv0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e19a199-0b9a-488d-8b00-97e49ed5729f",
   "metadata": {},
   "source": [
    "### act1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97ec681-83b9-4585-a937-862ae90a6661",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_conv2 = conv(fix_act0,filters2,bias2,stride=1,pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a707f846-356f-4d1d-82b2-65b877373350",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_ReLU2 = ReLU_4D(layer_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeaa0b5-8da9-44dc-a72d-fdd40a2176e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_avgpool2 = avgpool2d(layer_ReLU2,(2,2),2,pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2fdbc4-b15c-4002-8175-0a8693ee5857",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_avgpool2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542f6201-c8c4-44ea-be0a-ab52be8a1e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "act1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41996925-65cc-4bf8-93ce-f08c57b3ca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_act1 = torch.zeros(16,16,5,5)\n",
    "\n",
    "total = 0\n",
    "num = 0\n",
    "\n",
    "for a in range(16) :\n",
    "    for b in range(16) :\n",
    "        for c in range(5) :\n",
    "            for d in range(5) :\n",
    "                fix_act1[a][b][c][d] = flp2fix(layer_avgpool2[a][b][c][d],args.full_bits,args.frac_bits).fFull\n",
    "                if (torch.equal(fix_act1[a][b][c][d],act1[a][b][c][d])==False):\n",
    "                    num += 1\n",
    "                    print(fix_act1[a][b][c][d].item())\n",
    "                    print(act1[a][b][c][d].item())\n",
    "                total += 1\n",
    "\n",
    "print(\"number of different value is : {num}/{total}\".format(num=num,total=total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb65f3d-5088-4223-816f-9da415725f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(fix_act1,act1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f3cd71-8a41-49ba-846b-d1755d7cabeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "qmodel_layer_conv2 = qmodel.Conv2d2(fix_act0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ef531d-5010-42d8-b370-574977814e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(layer_conv2,qmodel_layer_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b037533d-31a6-444a-9523-135d9709b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "qmodel_layer_ReLU2 = qmodel.ReLU(qmodel_layer_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72df75c8-ba80-44fa-bffd-b513ab78ea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(layer_ReLU2,qmodel_layer_ReLU2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc7bd2c-c64b-45b1-af66-12583c1d742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "num = 0\n",
    "\n",
    "for a in range(16) :\n",
    "    for b in range(16) :\n",
    "        for c in range(10) :\n",
    "            for d in range(10) :\n",
    "                if (torch.equal(layer_ReLU2[a][b][c][d],qmodel_layer_ReLU2[a][b][c][d])==False):\n",
    "                    num += 1\n",
    "                total += 1\n",
    "\n",
    "print(\"number of different value is : {num}/{total}\".format(num=num,total=total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fa28b7-1dd1-4c5b-91af-a54f2e9ffbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "qmodel_layer_avgpool2 = qmodel.AvgPool2d(qmodel_layer_ReLU2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a298fd-76ea-4195-9cb3-48c9dd63245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qmodel_fix_act1 = torch.zeros(16,16,5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51655bfd-fdca-4724-b088-713dd50f970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "num = 0\n",
    "\n",
    "for a in range(16) :\n",
    "    for b in range(16) :\n",
    "        for c in range(5) :\n",
    "            for d in range(5) :\n",
    "                qmodel_fix_act1[a][b][c][d] = flp2fix(qmodel_layer_avgpool2[a][b][c][d],args.full_bits,args.frac_bits).fFull\n",
    "                if (torch.equal(fix_act1[a][b][c][d],qmodel_fix_act1[a][b][c][d])==False):\n",
    "                    num += 1                \n",
    "                total += 1\n",
    "\n",
    "print(\"number of different value is : {num}/{total}\".format(num=num,total=total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad94aef8-9ecd-4cc3-996e-b03fba24bf34",
   "metadata": {},
   "source": [
    "### act2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7882e74-d68c-424b-b5d0-2e9e5533f780",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_conv3 = conv(fix_act1,filters3,bias3,stride=1,pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c7b56d-c09e-4235-a6bb-3e18b05e09a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_ReLU3 = ReLU_4D(layer_conv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358f7e44-72d7-4d10-9258-28ceee56962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "act2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd8cdd0-94d1-456a-8467-2dd41cb3a29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_act2 = torch.zeros(16,120,1,1)\n",
    "\n",
    "total = 0\n",
    "num = 0\n",
    "\n",
    "for a in range(16) :\n",
    "    for b in range(120) :\n",
    "        for c in range(1) :\n",
    "            for d in range(1) :\n",
    "                fix_act2[a][b][c][d] = flp2fix(layer_ReLU3[a][b][c][d],args.full_bits,args.frac_bits).fFull\n",
    "                if (torch.equal(fix_act2[a][b][c][d],act2[a][b][c][d])==False):\n",
    "                    num += 1\n",
    "                total += 1\n",
    "\n",
    "print(\"number of different value is : {num}/{total}\".format(num=num,total=total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11dca20-77d5-4da9-ab99-fef4727eb718",
   "metadata": {},
   "outputs": [],
   "source": [
    "qmodel_layer_conv3 = qmodel.Conv2d3(fix_act1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4a895b-f115-45fd-85ba-7ec6dda741e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(layer_conv3,qmodel_layer_conv3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b08aaf-1fa8-4574-8509-b789b65b4ac6",
   "metadata": {},
   "source": [
    "### flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18349f05-8300-4b57-8fb3-293961ff2433",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_act2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fb10b1-c0b0-40c1-93ee-1781043285e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_act3 = fix_act2.view(16,120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812c4219-38d3-4708-a3c4-f966da5315ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_act3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688241de-a700-4df3-bbdb-9986bb966d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_act3 = torch.zeros(16,120)\n",
    "\n",
    "total = 0\n",
    "num = 0\n",
    "\n",
    "for a in range(16) :\n",
    "    for b in range(120) :\n",
    "                fix_act3[a][b] = flp2fix(layer_act3[a][b],args.full_bits,args.frac_bits).fFull\n",
    "                if (torch.equal(fix_act3[a][b],act3[a][b])==False):\n",
    "                    num += 1\n",
    "                total += 1\n",
    "\n",
    "print(\"number of different value is : {num}/{total}\".format(num=num,total=total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc809152-ee31-4a8c-8ed4-76150a013c56",
   "metadata": {},
   "source": [
    "### fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584f3423-7ca8-4876-9233-04284997f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc1 = torch.matmul(fix_act3,linear_filter1.t()) + linear_bias1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef808856-eec6-42a8-9853-0873238fb0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4674ea-37a2-4db8-ae63-eceb89df0a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc_ReLU1 = ReLU_2D(layer_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82461d60-1342-4d06-a1b1-1942ca87df39",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_act4 = torch.zeros(16,84)\n",
    "\n",
    "total = 0\n",
    "num = 0\n",
    "\n",
    "for a in range(16) :\n",
    "    for b in range(84) :\n",
    "                fix_act4[a][b] = flp2fix(layer_fc_ReLU1[a][b],args.full_bits,args.frac_bits).fFull\n",
    "                if (torch.equal(fix_act4[a][b],act4[a][b])==False):\n",
    "                    num += 1\n",
    "                total += 1\n",
    "\n",
    "print(\"number of different value is : {num}/{total}\".format(num=num,total=total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbec1fe4-1693-474c-90de-60d00b6c8012",
   "metadata": {},
   "source": [
    "### fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dd086f-5d62-495a-800f-45aaf183295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc2 = torch.matmul(fix_act4,linear_filter2.t()) + linear_bias2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ccc08d-0b74-42e8-acfb-1d5fceb4addd",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8800087-6b14-49c7-82b4-86033c1ef1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fix_act5 = torch.zeros(16,10)\n",
    "\n",
    "total = 0\n",
    "num = 0\n",
    "\n",
    "for a in range(16) :\n",
    "    for b in range(10) :\n",
    "                fix_act5[a][b] = flp2fix(layer_fc2[a][b],args.full_bits,args.frac_bits).fFull\n",
    "                if (torch.equal(fix_act5[a][b],act5[a][b])==False):\n",
    "                    num += 1\n",
    "                total += 1\n",
    "\n",
    "print(\"number of different value is : {num}/{total}\".format(num=num,total=total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94693a80-c055-4eb3-9274-0ce4755cf433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eece828f-4faa-4502-85e4-eb16109dcc5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
