{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2406a7df-f282-4b93-8c2b-40f19a124858",
   "metadata": {},
   "source": [
    "# Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8163a630-1c4d-4dc8-97ff-8540ed7b8c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7774703-6107-4a6b-a887-5e9d15146291",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.remove('/home/jungeun/.local/lib/python3.6/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f9693f8-f091-4426-a2ca-0a7876787667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a97e973-bc3a-42d2-a2ae-ea8d2da98fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/jungeun/.local/lib/python3.6/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c465ce86-0999-4673-a94b-b34654a032f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from tqdm import tqdm_notebook as tq\n",
    "import tqdm\n",
    "import os, time, math, copy\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.set_printoptions(precision=8, linewidth=50000)\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92c4219-8b88-463d-b57d-dd02e947a64f",
   "metadata": {},
   "source": [
    "# Print Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "056d873c-4a0d-4de1-860d-6f604a48fa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACK\t= '\\033[30m'\n",
    "RED\t\t= '\\033[31m'\n",
    "GREEN\t= '\\033[32m'\n",
    "YELLOW\t= '\\033[33m'\n",
    "BLUE\t= '\\033[34m'\n",
    "MAGENTA\t= '\\033[35m'\n",
    "CYAN\t= '\\033[36m'\n",
    "RESET\t= '\\033[0m'\n",
    "SEL\t\t= '\\033[7m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b64058b7-984f-4bd5-bc1c-3297042c62d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fxp:\n",
    "    def __init__(self, bIn, iBWF):\n",
    "        self.iFullBW = len(bIn)\n",
    "        self.iIntgBW = self.iFullBW - iBWF\n",
    "        self.bSign   = bIn[0]\n",
    "        self.bIntg   = bIn[:self.iIntgBW]\n",
    "        self.bFrac   = bIn[self.iIntgBW:]\n",
    "        self.fFull   = 0\n",
    "        try:\n",
    "            for idx, bit in enumerate(bIn):\n",
    "                if idx == 0:\n",
    "                    self.fFull = self.fFull + int(bit,2) * -pow(2, self.iIntgBW - 1)\n",
    "                else:\n",
    "                    self.fFull = self.fFull + int(bit,2) * pow(2, self.iIntgBW - 1 - idx)\n",
    "        except:\n",
    "            print(bIn)\n",
    "        self.dispFull = RED + self.bIntg + BLUE + self.bFrac + RESET\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae69422b-795b-4e2b-9b2c-63702c4aa2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class flp2fix:\n",
    "    def __init__(self, fIn, iBW, iBWF):\n",
    "        self.fMin = - 2 ** (iBW - iBWF - 1)\n",
    "        self.fMax = (2 ** (iBW-1) - 1) * (2 ** -iBWF)\n",
    "        self.fResol = 2 ** -iBWF\n",
    "        #if fIn < self.fMin or fIn > self.fMax:\n",
    "            #print(f'({fIn}): Out of input range ({self.fMax}/{self.fMin}) during flp -> fix converting ')\n",
    "        self.iBW = iBW\n",
    "        self.iBWI = iBW - iBWF\n",
    "        self.iBWF = iBWF\n",
    "\n",
    "        self.iFLP2INT = abs(int(fIn * 2 ** iBWF))\n",
    "        if fIn < 0:\n",
    "            self.iFLP2INT = 2 ** (iBW-1) - self.iFLP2INT\n",
    "\n",
    "        if fIn >= 0:\n",
    "            self.bFull = bin(self.iFLP2INT)[2:].rjust(iBW, '0')\n",
    "        else:\n",
    "            self.bFull = '1'+bin(self.iFLP2INT)[2:].rjust(iBW-1, '0')\n",
    "            if len(self.bFull) > iBW:\n",
    "                self.bFull = '0' * iBW\n",
    "\n",
    "        self.cssFxp = fxp(self.bFull, self.iBWF)\n",
    "        self.bSign = self.cssFxp.bSign\n",
    "        self.bIntg = self.cssFxp.bIntg\n",
    "        self.bFrac = self.cssFxp.bFrac\n",
    "        self.fFull = self.cssFxp.fFull\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d34d648-b811-4ee0-b518-3b10c97e7eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flp2fixTensor(fIn, iBW, iBWF,args):\n",
    "    fMin = - 2 ** (iBW - iBWF - 1)\n",
    "    fMax = (2 ** (iBW-1) - 1) * (2 ** -iBWF)\n",
    "    fList = []\n",
    "    for aTensor in fIn.view(-1):\n",
    "        fList.append(flp2fix(aTensor, iBW, iBWF).fFull)\n",
    "    return torch.tensor(fList).view(fIn.size())\n",
    "    fList = []\n",
    "    for aTensor in fIn.view(-1):\n",
    "        fList.append(flp2fix(aTensor, iBW, iBWF).fFull)\n",
    "    return (torch.tensor(fList).view(fIn.size())).to(args.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6562c1-c9bd-428a-9b1d-c19286c0bc9c",
   "metadata": {},
   "source": [
    "# User Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e84144fc-99bb-4e41-bdbf-5349ea1162e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '~/dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea932772-49ae-4b5b-bae7-a6188c2f3f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch for MNIST dataset')\n",
    "parser.add_argument('--device', type=str, default='cuda', help='Device')\n",
    "parser.add_argument('--shuffle', action='store_true', default=False, help='enables data shuffle')\n",
    "parser.add_argument('--dataset', type=str, default='mnist', help='training dataset')\n",
    "parser.add_argument('--data_path', type=str, default=data_path, help='path to MNIST')\n",
    "parser.add_argument('--batch_size', type=int, default=64, help='batch size')\n",
    "parser.add_argument('--epochs', type=int, default=10, help='number of epochs to train')\n",
    "parser.add_argument('--lr', type=float, default=0.001, help='learning rate')\n",
    "parser.add_argument('--optimizer', type=str, default='adam', help='optimizer')\n",
    "parser.add_argument('--loss_func', type=str, default='cel', help='optimizer')\n",
    "parser.add_argument('--quant_opt', type=str, default='asym', help='Type of Quantization')\n",
    "parser.add_argument('--full_bits', type=int, default=16, help='Number of Quantization Bits')\n",
    "parser.add_argument('--frac_bits', type=int, default=8, help='Number of Quantization Bits')\n",
    "parser.add_argument('--pretrained', type=bool, default=True, help='Pretrained Model')\n",
    "parser.add_argument('--act_quant', type=bool, default=False, help='Activation Quantization')\n",
    "parser.add_argument('--disp', type=bool, default=False, help='Display Model Information')\n",
    "\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e302edf6-62d7-4b65-9ce5-6a3ac2c94aa0",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0cbdfa0b-c8b1-4aaa-8984-cbcca3c5c3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args.device == 'cuda' else {}\n",
    "if args.dataset == 'mnist':\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=datasets.MNIST(\n",
    "            root=args.data_path,\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=transforms.ToTensor()\n",
    "        ),\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=args.shuffle,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=datasets.MNIST(\n",
    "            root=args.data_path,\n",
    "            train=False,\n",
    "            download=True,\n",
    "            transform=transforms.ToTensor()\n",
    "        ),\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=args.shuffle,\n",
    "        **kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b293a232-6746-49e9-a243-92a946b05896",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7361cc63-0614-40dc-ada6-d539efe1994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28*28, 32)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, 64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        logits = self.fc3(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ed3f09d-808d-489d-a527-860dcf20bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genOptimizer(model, args):\n",
    "    if args.optimizer == 'sgd':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=args.lr)\n",
    "    if args.optimizer == 'adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    return optimizer\n",
    "\n",
    "def genLossFunc(args):\n",
    "    if args.loss_func == 'cel':\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "    return loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "348b7f57-d809-4d1b-91ab-64331e739a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, epoch, args):\n",
    "    model.train()\n",
    "    loss_func = genLossFunc(args)\n",
    "    optimizer = genOptimizer(model, args)\n",
    "    max_batch_index = int(np.floor(len(train_loader.dataset)/args.batch_size))\n",
    "    running_loss = 0\n",
    "    for batch_index, (image, label) in enumerate(tq(train_loader, desc='Train', leave=False)):\n",
    "        image, label = image.to(args.device), label.to(args.device)\n",
    "        pred = model(image)\n",
    "        loss = loss_func(pred, label)\n",
    "        running_loss += loss.item()#*image.size(0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1:<3d}: Avg. Loss: {running_loss/len(train_loader.dataset):.4f}', end = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d67808af-a32c-4c73-a36f-7e8de8b0e4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model, args):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loss_func = genLossFunc(args)\n",
    "        loss, correct = 0, 0\n",
    "#  for batch_index, (image, label) in enumerate(tq(test_loader, desc='Test', leave=False)):\n",
    "        for batch_index, (image, label) in enumerate(test_loader):\n",
    "            image, label = image.to(args.device), label.to(args.device)\n",
    "            pred = model(image)\n",
    "            loss += loss_func(pred, label).item()#*image.size(0)\n",
    "            correct += (pred.argmax(1) == label).type(torch.int).sum().item()\n",
    "    loss /= len(test_loader.dataset)\n",
    "    correct_rate = 100 * correct / len(test_loader.dataset)\n",
    "    print(f'Accuracy: {correct}/{len(test_loader.dataset)} ({correct_rate:>.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6be9b886-0a76-4d8d-baf7-987b4fdec1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model):\n",
    "    for epoch in range(args.epochs):\n",
    "        train(train_loader, model, epoch, args)\n",
    "        test(test_loader, model, args)\n",
    "    print(\"Done!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32f8f899-6bb3-442a-a879-e204b693a944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 9679/10000 (96.8%)\n"
     ]
    }
   ],
   "source": [
    "if args.pretrained:\n",
    "    if os.path.isfile('preTrainedModel.pth'):\n",
    "        model = MLP().to(args.device)\n",
    "        model.load_state_dict(torch.load('preTrainedModel.pth'))\n",
    "        test(test_loader, model, args)\n",
    "    else:\n",
    "        model = main(MLP().to(args.device))\n",
    "        torch.save(model.state_dict(), 'preTrainedModel.pth')\n",
    "else:\n",
    "\tmodel = main(MLP().to(args.device))\n",
    "\ttorch.save(model.state_dict(), 'preTrainedModel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d113cc44-8936-42f4-9edc-d5a9500c3ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2fix(model, args):\n",
    "\tfor name, _ in model.named_parameters():\n",
    "\t\texec(f'model.{name}.data = flp2fixTensor(model.{name}.data, {args.full_bits}, {args.frac_bits}, args)')\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "450e4437-1f3c-4976-bf36-f66da4b8fd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantFixForward(model, x, args):\n",
    "\tcmodel = copy.deepcopy(model).to(args.device)\n",
    "\twith torch.no_grad():\n",
    "\t\tx = cmodel.flatten(x).to(args.device)\n",
    "\t\tact0 = flp2fixTensor(x, args.full_bits, args.frac_bits, args).to(args.device)\n",
    "\t\t\n",
    "\t\tact1 = model.relu1(cmodel.fc1(act0)).to(args.device)\n",
    "\t\tact1 = flp2fixTensor(act1, args.full_bits, args.frac_bits, args).to(args.device)\n",
    "\n",
    "\t\tact2 = cmodel.relu2(cmodel.fc2(act1)).to(args.device)\n",
    "\t\tact2 = flp2fixTensor(act2, args.full_bits, args.frac_bits, args).to(args.device)\n",
    "\t\t\n",
    "\t\tact3 = cmodel.fc3(act2).to(args.device)\n",
    "\t\tact3 = flp2fixTensor(act3, args.full_bits, args.frac_bits, args).to(args.device)\n",
    "\treturn cmodel, act0, act1, act2, act3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a41e1a82-82ee-42fa-9f7f-8ff0981e3d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testQuant(model, test_loader, args):\n",
    "\tqmodel = copy.deepcopy(model).to(args.device)\n",
    "\tqmodel = model2fix(qmodel, args)\n",
    "\tqmodel.eval()\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\tloss_func = genLossFunc(args)\n",
    "\t\tloss, correct = 0, 0\n",
    "\t\tfor batch_index, (image, label) in enumerate(tq(test_loader,desc='Test',leave=False)):\n",
    "\t\t\timage, label = image.to(args.device), label.to(args.device)\n",
    "\t\t\tqmodel, act0, act1, act2, act3  = quantFixForward(qmodel, image, args)\n",
    "\t\t\ty = act3\n",
    "\t\t\tloss += loss_func(y, label).item()#*image.size(0)\n",
    "\t\t\tcorrect += (y.argmax(1) == label).type(torch.int).sum().item()\n",
    "\tcorrect_rate = 100 * correct / len(test_loader.dataset)\n",
    "\tprint(f'Accuracy: {correct}/{len(test_loader.dataset)} ({correct_rate:>.1f}%) Loss: {loss/len(test_loader.dataset):.2f}')\n",
    "\treturn qmodel, act0, act1, act2, act3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "824c658d-8ac0-41cf-afec-21c721f67ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 9677/10000 (96.8%) Loss: 0.00\n"
     ]
    }
   ],
   "source": [
    "qmodel, act0, act1, act2, act3 = testQuant(model, test_loader, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c64c18aa-7e1b-4c62-a38c-f6184d9751b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractParams(model, args):\n",
    "\tout_path = './mif'\n",
    "\tos.system(f'rm -rf {out_path};mkdir -p {out_path}')\n",
    "\tfor key in model.state_dict().keys():\n",
    "\t\tlayer_name = key.split('.')[0]\n",
    "\t\tparam_type = 'w' if 'weight' in key else 'b'\n",
    "\t\tfor idx, params in enumerate(eval(f'qmodel.{key}.data')):\n",
    "\t\t\twith open(f'{out_path}/{layer_name}_{param_type}_{idx}.mif', 'w') as fh:\n",
    "\t\t\t\tif param_type == 'w':\n",
    "\t\t\t\t\tfor idx, param in enumerate(params):\n",
    "\t\t\t\t\t\tbin_param = flp2fix(param, args.full_bits, args.frac_bits).bFull\n",
    "\t\t\t\t\t\tfh.write(bin_param + ('\\n','')[idx == len(params)-1])\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tbin_param = flp2fix(params, args.full_bits, args.frac_bits).bFull\n",
    "\t\t\t\t\tfh.write(bin_param)\n",
    "\t\t\t\t\t\n",
    "def genInputVector(test_loader, args):\n",
    "\tout_path = './vec'\n",
    "\tos.system(f'rm -rf {out_path};mkdir -p {out_path}')\n",
    "\twith open(f'{out_path}/labels.vec', 'w') as fh_labels:\n",
    "\t\twith open(f'{out_path}/images.vec', 'w') as fh_images:\n",
    "\t\t\tfor batch_index, (images, labels) in enumerate(test_loader):\n",
    "\t\t\t\tfor (image, label) in zip(images, labels):\n",
    "\t\t\t\t\tbin_label = flp2fix(label, args.full_bits, 0).bFull\n",
    "\t\t\t\t\tfh_labels.write(bin_label+'\\n')\n",
    "\t\t\t\t\tfor pixel in image.view(-1):\n",
    "\t\t\t\t\t\tbin_pixel = flp2fix(pixel, args.full_bits, args.frac_bits).bFull\n",
    "\t\t\t\t\t\tfh_images.write(bin_pixel+'\\n')\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8edc5e3-9f3e-4b7c-acf6-8c9ed7b463a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractParams(model, args)\n",
    "genInputVector(test_loader, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e72baa5-e126-4041-a02c-b1ac6ceae86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genFPGAInput(test_loader, args):\n",
    "\tout_path = './bin'\n",
    "\tos.system(f'rm -rf {out_path};mkdir -p {out_path}')\n",
    "\twith open(f'{out_path}/labels.bin', 'wb') as fh_labels:\n",
    "\t\twith open(f'{out_path}/images.bin', 'wb') as fh_images:\n",
    "\t\t\tfor batch_index, (images, labels) in enumerate(test_loader):\n",
    "\t\t\t\tfor (image, label) in zip(images, labels):\n",
    "\t\t\t\t\tbin_label = flp2fix(label, args.full_bits, 0).bFull\n",
    "\t\t\t\t\tfh_labels.write(bytes([int(bin_label[8:], 2)]))\n",
    "\t\t\t\t\tfh_labels.write(bytes([int(bin_label[:8], 2)]))                    \n",
    "\t\t\t\t\tfor pixel in image.view(-1):\n",
    "\t\t\t\t\t\tbin_pixel = flp2fix(pixel, args.full_bits, args.frac_bits).bFull\n",
    "\t\t\t\t\t\tfh_images.write(bytes([int(bin_pixel[8:], 2)]))\n",
    "\t\t\t\t\t\tfh_images.write(bytes([int(bin_pixel[:8], 2)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e09f2bc0-69b6-4372-87aa-be839d24b316",
   "metadata": {},
   "outputs": [],
   "source": [
    "genFPGAInput(test_loader, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f23439e5-8805-4656-8592-ca60a6dea344",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mifFile in os.listdir('./mif'):\n",
    "    binPath = './bin'\n",
    "    mifPath = './mif'\n",
    "    binFile = mifFile.split('.')[0] + '.bin'\n",
    "    with open(f'{binPath}/{binFile}', 'wb') as fh_bin:\n",
    "        with open(f'{mifPath}/{mifFile}', 'r') as fh_mif:\n",
    "            for line in fh_mif.read().splitlines():\n",
    "                fh_bin.write(bytes([int(line[8:], 2)]))\n",
    "                fh_bin.write(bytes([int(line[:8], 2)]))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd31c40-2cf0-4a4c-9a29-b53c22be68bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
