{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2406a7df-f282-4b93-8c2b-40f19a124858",
   "metadata": {},
   "source": [
    "# Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c465ce86-0999-4673-a94b-b34654a032f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: libc10_cuda.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from tqdm import tqdm_notebook as tq\n",
    "import tqdm\n",
    "import os, time, math, copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "torch.set_printoptions(precision=8, linewidth=50000)\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92c4219-8b88-463d-b57d-dd02e947a64f",
   "metadata": {},
   "source": [
    "# Print Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "056d873c-4a0d-4de1-860d-6f604a48fa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACK\t= '\\033[30m'\n",
    "RED\t\t= '\\033[31m'\n",
    "GREEN\t= '\\033[32m'\n",
    "YELLOW\t= '\\033[33m'\n",
    "BLUE\t= '\\033[34m'\n",
    "MAGENTA\t= '\\033[35m'\n",
    "CYAN\t= '\\033[36m'\n",
    "RESET\t= '\\033[0m'\n",
    "SEL\t\t= '\\033[7m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30e492f0-1f92-4f95-96f3-533114164d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int2bin(iIn,iBW):\n",
    "    iBW = iBW + 1\n",
    "    if iIn >= 0:\n",
    "        bOut = bin(iIn).replace('0b','').rjust(iBW,'0')\n",
    "    else :\n",
    "        bOut = bin(iIn & (pow(2,iBW)-1)).replace('0b','').rjust(iBW,'1')\n",
    "    return bOut[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3353766-05ef-47ea-98ea-8c8337997da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XOR(iA,iB):\n",
    "    if iA != iB :\n",
    "        iOut = '1'\n",
    "    else : \n",
    "        iOut = '0'\n",
    "    return iOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71104da7-f503-4e52-9c40-55718be6854b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def snum(a):\n",
    "    if a >= 0 :\n",
    "        return '0'\n",
    "    else :\n",
    "        return '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b64058b7-984f-4bd5-bc1c-3297042c62d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fxp:\n",
    "    def __init__(self, bIn, iBWF):\n",
    "        self.iFullBW = len(bIn)\n",
    "        self.iIntgBW = self.iFullBW - iBWF\n",
    "        self.bSign = bIn[0]\n",
    "        self.bIntg = bIn[:self.iIntgBW]\n",
    "        self.bFrac = bIn[self.iIntgBW:]\n",
    "        self.fFull = 0\n",
    "        try:\n",
    "            for idx, bit in enumerate(bIn):\n",
    "                if idx == 0:\n",
    "                    self.fFull = self.fFull + int(bit,2) * -pow(2, self.iIntgBW - 1)\n",
    "                else:\n",
    "                    self.fFull = self.fFull + int(bit,2) * pow(2, self.iIntgBW - 1 - idx)\n",
    "        except:\n",
    "            print(bIn)\n",
    "        self.dispFull = self.bIntg +\".\"+ self.bFrac \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae69422b-795b-4e2b-9b2c-63702c4aa2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class flp2fix:\n",
    "    def __init__(self, fIn, iBW, iBWF):\n",
    "        self.fMin = - 2 ** (iBW - iBWF - 1)\n",
    "        self.fMax = (2 ** (iBW-1) - 1) * (2 ** -iBWF)\n",
    "        self.fResol = 2 ** -iBWF\n",
    "        #if fIn < self.fMin or fIn > self.fMax:\n",
    "            #print(f'({fIn}): Out of input range ({self.fMax}/{self.fMin}) during flp -> fix converting ')\n",
    "        self.iBW = iBW\n",
    "        self.iBWI = iBW - iBWF\n",
    "        self.iBWF = iBWF\n",
    "\n",
    "        self.iFLP2INT = abs(int(fIn * 2 ** iBWF))\n",
    "        if fIn < 0:\n",
    "            self.iFLP2INT = 2 ** (iBW-1) - self.iFLP2INT\n",
    "\n",
    "        if fIn >= 0:\n",
    "            self.bFull = bin(self.iFLP2INT)[2:].rjust(iBW, '0')\n",
    "        else:\n",
    "            self.bFull = '1'+bin(self.iFLP2INT)[2:].rjust(iBW-1, '0')\n",
    "            if len(self.bFull) > iBW:\n",
    "                self.bFull = '0' * iBW\n",
    "\n",
    "        self.cssFxp = fxp(self.bFull, self.iBWF)\n",
    "        self.bSign = self.cssFxp.bSign\n",
    "        self.bIntg = self.cssFxp.bIntg\n",
    "        self.bFrac = self.cssFxp.bFrac\n",
    "        self.fFull = self.cssFxp.fFull\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d34d648-b811-4ee0-b518-3b10c97e7eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flp2fixTensor(fIn, iBW, iBWF):\n",
    "    fMin = - 2 ** (iBW - iBWF - 1)\n",
    "    fMax = (2 ** (iBW-1) - 1) * (2 ** -iBWF)\n",
    "    fList = []\n",
    "    for aTensor in fIn.view(-1):\n",
    "        fList.append(flp2fix(aTensor, iBW, iBWF).fFull)\n",
    "    return torch.tensor(fList).view(fIn.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6562c1-c9bd-428a-9b1d-c19286c0bc9c",
   "metadata": {},
   "source": [
    "# User Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e84144fc-99bb-4e41-bdbf-5349ea1162e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '~/dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea932772-49ae-4b5b-bae7-a6188c2f3f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch for MNIST dataset')\n",
    "parser.add_argument('--device', type=str, default='cpu', help='Device')\n",
    "parser.add_argument('--shuffle', action='store_true', default=False, help='enables data shuffle')\n",
    "parser.add_argument('--dataset', type=str, default='mnist', help='training dataset')\n",
    "parser.add_argument('--data_path', type=str, default=data_path, help='path to MNIST')\n",
    "parser.add_argument('--batch_size', type=int, default=64, help='batch size')\n",
    "parser.add_argument('--epochs', type=int, default=10, help='number of epochs to train')\n",
    "parser.add_argument('--lr', type=float, default=0.001, help='learning rate')\n",
    "parser.add_argument('--optimizer', type=str, default='adam', help='optimizer')\n",
    "parser.add_argument('--loss_func', type=str, default='cel', help='optimizer')\n",
    "parser.add_argument('--quant_opt', type=str, default='asym', help='Type of Quantization')\n",
    "parser.add_argument('--full_bits', type=int, default=16, help='Number of Quantization Bits')\n",
    "parser.add_argument('--frac_bits', type=int, default=7, help='Number of Quantization Bits')\n",
    "#parser.add_argument('--pretrained', type=bool, default=True, help='Pretrained Model')\n",
    "parser.add_argument('--act_quant', type=bool, default=False, help='Activation Quantization')\n",
    "parser.add_argument('--disp', type=bool, default=False, help='Display Model Information')\n",
    "parser.add_argument('--bBW',type=int,default=7,help='bit number')\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e302edf6-62d7-4b65-9ce5-6a3ac2c94aa0",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cbdfa0b-c8b1-4aaa-8984-cbcca3c5c3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args.device == 'cuda' else {}\n",
    "if args.dataset == 'mnist':\n",
    "\ttrain_loader = torch.utils.data.DataLoader(\n",
    "\t\tdataset=datasets.MNIST(\n",
    "\t\t\troot=args.data_path,\n",
    "\t\t\ttrain=True,\n",
    "\t\t\tdownload=True,\n",
    "\t\t\ttransform=transforms.ToTensor()\n",
    "\t\t),\n",
    "\t\tbatch_size=args.batch_size,\n",
    "\t\tshuffle=args.shuffle,\n",
    "\t\t**kwargs\n",
    "\t)\n",
    "\n",
    "\ttest_loader = torch.utils.data.DataLoader(\n",
    "\t\tdataset=datasets.MNIST(\n",
    "\t\t\troot=args.data_path,\n",
    "\t\t\ttrain=False,\n",
    "\t\t\tdownload=True,\n",
    "\t\t\ttransform=transforms.ToTensor()\n",
    "\t\t),\n",
    "\t\tbatch_size=args.batch_size,\n",
    "\t\tshuffle=args.shuffle,\n",
    "\t\t**kwargs\n",
    "\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b293a232-6746-49e9-a243-92a946b05896",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7361cc63-0614-40dc-ada6-d539efe1994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(MLP, self).__init__()\n",
    "\t\tself.flatten = nn.Flatten()\n",
    "\t\tself.fc1 = nn.Linear(28*28, 32)\n",
    "\t\tself.relu1 = nn.ReLU()\n",
    "\t\tself.fc2 = nn.Linear(32, 64)\n",
    "\t\tself.relu2 = nn.ReLU()\n",
    "\t\tself.fc3 = nn.Linear(64, 10)\n",
    "\t\t\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.flatten(x)\n",
    "\t\tx = self.fc1(x)\n",
    "\t\tx = self.relu1(x)\n",
    "\t\tx = self.fc2(x)\n",
    "\t\tx = self.relu2(x)\n",
    "\t\tlogits = self.fc3(x)\n",
    "\t\treturn logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ed3f09d-808d-489d-a527-860dcf20bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genOptimizer(model, args):\n",
    "\tif args.optimizer == 'sgd':\n",
    "\t\toptimizer = torch.optim.SGD(model.parameters(), lr=args.lr)\n",
    "\tif args.optimizer == 'adam':\n",
    "\t\toptimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\treturn optimizer\n",
    "\n",
    "def genLossFunc(args):\n",
    "\tif args.loss_func == 'cel':\n",
    "\t\tloss_func = nn.CrossEntropyLoss()\n",
    "\treturn loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "348b7f57-d809-4d1b-91ab-64331e739a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, epoch, args):\n",
    "\tmodel.train()\n",
    "\tloss_func = genLossFunc(args)\n",
    "\toptimizer = genOptimizer(model, args)\n",
    "\tmax_batch_index = int(np.floor(len(train_loader.dataset)/args.batch_size))\n",
    "\trunning_loss = 0\n",
    "\tfor batch_index, (image, label) in enumerate(tq(train_loader, desc='Train', leave=False)):\n",
    "\t\timage, label = image.to(args.device), label.to(args.device)\n",
    "\t\tpred = model(image)\n",
    "\t\tloss = loss_func(pred, label)\n",
    "\t\trunning_loss += loss.item()#*image.size(0)\n",
    "\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\t\t\t\n",
    "\tprint(f'Epoch {epoch+1:<3d}: Avg. Loss: {running_loss/len(train_loader.dataset):.4f}', end = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d67808af-a32c-4c73-a36f-7e8de8b0e4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model, args):\n",
    "\tmodel.eval()\n",
    "\twith torch.no_grad():\n",
    "\t\tloss_func = genLossFunc(args)\n",
    "\t\tloss, correct = 0, 0\n",
    "# \t\tfor batch_index, (image, label) in enumerate(tq(test_loader, desc='Test', leave=False)):\n",
    "\t\tfor batch_index, (image, label) in enumerate(test_loader):\n",
    "\t\t\timage, label = image.to(args.device), label.to(args.device)\n",
    "\t\t\tpred = model(image)\n",
    "\t\t\tloss += loss_func(pred, label).item()#*image.size(0)\n",
    "\t\t\tcorrect += (pred.argmax(1) == label).type(torch.int).sum().item()\n",
    "\tloss /= len(test_loader.dataset)\n",
    "\tcorrect_rate = 100 * correct / len(test_loader.dataset)\n",
    "\tprint(f'Accuracy: {correct}/{len(test_loader.dataset)} ({correct_rate:>.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6be9b886-0a76-4d8d-baf7-987b4fdec1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model):\n",
    "\tfor epoch in range(args.epochs):\n",
    "\t\ttrain(train_loader, model, epoch, args)\n",
    "\t\ttest(test_loader, model, args)\n",
    "\tprint(\"Done!\")\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32f8f899-6bb3-442a-a879-e204b693a944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1  : Avg. Loss: 0.0072\tAccuracy: 9253/10000 (92.5%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2  : Avg. Loss: 0.0034\tAccuracy: 9403/10000 (94.0%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3  : Avg. Loss: 0.0026\tAccuracy: 9534/10000 (95.3%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4  : Avg. Loss: 0.0022\tAccuracy: 9587/10000 (95.9%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5  : Avg. Loss: 0.0019\tAccuracy: 9596/10000 (96.0%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6  : Avg. Loss: 0.0017\tAccuracy: 9615/10000 (96.2%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7  : Avg. Loss: 0.0015\tAccuracy: 9634/10000 (96.3%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8  : Avg. Loss: 0.0013\tAccuracy: 9637/10000 (96.4%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9  : Avg. Loss: 0.0012\tAccuracy: 9641/10000 (96.4%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 : Avg. Loss: 0.0011\tAccuracy: 9654/10000 (96.5%)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#if args.pretrained:\n",
    "#    if os.path.isfile('preTrainedModel.pth'):\n",
    "#        model = MLP().to(args.device)\n",
    "#        model.load_state_dict(torch.load('preTrainedModel.pth'))\n",
    "#        test(test_loader, model, args)\n",
    "#    else:\n",
    "#        model = main(MLP().to(args.device))\n",
    "#        torch.save(model.state_dict(), 'preTrainedModel.pth')\n",
    "#else:\n",
    "model = main(MLP().to(args.device))\n",
    "torch.save(model.state_dict(), 'preTrainedModel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08ebbf45-272c-43f6-890a-9239c05ee74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.02683339, -0.01054859,  0.03032732,  ...,  0.01771713,  0.01221379, -0.02618989],\n",
      "        [-0.01719414,  0.01315976,  0.01165506,  ...,  0.01930584,  0.02855700,  0.00489422],\n",
      "        [ 0.01752516, -0.03049587, -0.01644560,  ..., -0.00689845, -0.01012152,  0.01757649],\n",
      "        ...,\n",
      "        [ 0.01941297,  0.02264481, -0.00148786,  ..., -0.00716893, -0.02862862,  0.00629433],\n",
      "        [ 0.02069288, -0.02025052,  0.01866948,  ...,  0.01830390, -0.01152918,  0.00178513],\n",
      "        [-0.03558008,  0.00286253,  0.03205480,  ...,  0.00888480, -0.02736063, -0.02299960]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.fc1.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37182dc5-06c8-49df-b1f5-f72fbece445a",
   "metadata": {},
   "source": [
    "# SNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad450f97-2553-48dc-9089-a553b1c26a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Comp(a,lfsr,snum):\n",
    "    for com in range(0,len(a)):\n",
    "        oA = '0'\n",
    "        if a[com]!=lfsr[com]:\n",
    "            if(int(a[com]) > int(lfsr[com])):\n",
    "                oA = '1'\n",
    "            break\n",
    "    return XOR(oA,snum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "846fbf5c-f091-4e53-ac91-0380b1971433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perm(a):\n",
    "    al = len(a)\n",
    "    blist = []\n",
    "    for i in range(al) :\n",
    "        #print(al-i-1)\n",
    "        blist.append(a[al-i-1])\n",
    "    \n",
    "    b = \"\".join(blist)\n",
    "    \n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74eced07-5e7a-4bf7-9e7b-e913117dd69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LFSR7:\n",
    "    def Random(self):\n",
    "        self.b0 = eval(f'str(random.randint(0,1))')\n",
    "        self.b1 = eval(f'str(random.randint(0,1))')\n",
    "        self.b2 = eval(f'str(random.randint(0,1))')\n",
    "        self.b3 = eval(f'str(random.randint(0,1))')\n",
    "        self.b4 = eval(f'str(random.randint(0,1))')\n",
    "        self.b5 = eval(f'str(random.randint(0,1))')\n",
    "        self.b6 = eval(f'str(random.randint(0,1))')\n",
    "        \n",
    "        return self.b0 + self.b1 + self.b2 + self.b3 + self.b4 + self.b5 + self.b6\n",
    "    \n",
    "    def Normal(self,stream):\n",
    "        self.b0 = XOR(int(stream[5]),int(stream[6]))\n",
    "        self.b1 = stream[0]\n",
    "        self.b2 = stream[1]\n",
    "        self.b3 = stream[2]\n",
    "        self.b4 = stream[3]\n",
    "        self.b5 = stream[4]\n",
    "        self.b6 = stream[5]\n",
    "        \n",
    "        return self.b0 + self.b1 + self.b2 + self.b3 + self.b4 + self.b5 + self.b6\n",
    "    \n",
    "    def Allzero(self):\n",
    "        self.b0 = '0'\n",
    "        self.b1 = '0'\n",
    "        self.b2 = '0'\n",
    "        self.b3 = '0'\n",
    "        self.b4 = '0'\n",
    "        self.b5 = '0'\n",
    "        self.b6 = '0'\n",
    "        \n",
    "        return self.b0 + self.b1 + self.b2 + self.b3 + self.b4 + self.b5 + self.b6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57602a46-d008-405e-baa8-91ccdccc2e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LFSRlist7():\n",
    "    lfsr = LFSR7()\n",
    "    lfsrlist = []\n",
    "    for k in range(2**(7)-1): #lfsr number generating\n",
    "        if k == 0:\n",
    "            lfsrlist.append(lfsr.Random())\n",
    "        else :\n",
    "            lfsrlist.append(lfsr.Normal(lfsrlist[k-1]))\n",
    "        if (k == 2**(7)-2):\n",
    "            lfsrlist.append(lfsr.Allzero())\n",
    "    \n",
    "    if (args.bBW) != args.frac_bits :\n",
    "        if args.bBW < args.frac_bits :\n",
    "            for i in range(len(lfsrlist)):\n",
    "                lfsrlist[i] = lfsrlist[i] + (args.frac_bits-args.bBW)*'0'\n",
    "        else :\n",
    "            print(\"it can't work\")\n",
    "            return 0\n",
    "    \n",
    "    return lfsrlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7228b31a-6b0b-4c39-955f-ff013af6f135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SNG(iIN,lfsr):\n",
    "\n",
    "    sNUM = snum(iIN)\n",
    "    \n",
    "    bIN = flp2fix(iIN,args.full_bits,args.frac_bits).bFull\n",
    "    bFRAC = bIN[-(args.frac_bits):]\n",
    "    if sNUM == 1 :\n",
    "        bFRAC = bin(int(binInv(bFRAC),2)+1).replace('0b','').rjust(args.bBW,'0')\n",
    "    oAlist = []\n",
    "    \n",
    "    for k in range(2**(args.bBW)): #lfsr number generating\n",
    "        lNUM = lfsr[k]\n",
    "        a = Comp(bFRAC,lNUM,sNUM)\n",
    "        oAlist.append(a) #comparator of input a\n",
    "    \n",
    "    oAlist.insert(0,sNUM)\n",
    "    sA = \"\".join(oAlist)\n",
    "    if bIN == '0'*args.full_bits :\n",
    "        return \"0\"*((2**(args.bBW))+1)\n",
    "    else :\n",
    "        return sA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7c9677e-0f1e-4631-87c1-3203cd379305",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def SNG_P(iIN,lfsr):\n",
    "    sNUM = snum(iIN)\n",
    "    \n",
    "    bIN = flp2fix(iIN,args.full_bits,args.frac_bits).bFull\n",
    "    bFRAC = bIN[-(args.frac_bits):]\n",
    "    if sNUM == 1 :\n",
    "        bFRAC = bin(int(binInv(bFRAC),2)+1).replace('0b','').rjust(args.bBW,'0')\n",
    "    oAlist = []\n",
    "    \n",
    "    for k in range(2**(args.bBW)): #lfsr number generating\n",
    "        if (args.bBW == args.frac_bits) :    \n",
    "            lNUM = perm(lfsr[k])\n",
    "        elif (args.bBW < args.frac_bits) :\n",
    "            lNUM = perm(lfsr[k][:args.bBW])+(args.frac_bits-args.bBW)*\"0\"\n",
    "        a = Comp(bFRAC,lNUM,sNUM)\n",
    "        oAlist.append(a) #comparator of input a\n",
    "    \n",
    "    oAlist.insert(0,sNUM)\n",
    "    sA = \"\".join(oAlist)\n",
    "    if bIN == '0'*args.full_bits :\n",
    "        return \"0\"*((2**(args.bBW))+1)\n",
    "    else :\n",
    "        return sA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10217386-de1f-4517-a95d-20470789a30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SNGnumpy(fIn,lfsr):\n",
    "    start = time.time()\n",
    "    sList = []\n",
    "    for aNumpy in fIn.view(-1):\n",
    "        sList.append(SNG(float(aNumpy),lfsr))\n",
    "    end = time.time()\n",
    "    sec = (end-start)\n",
    "    result_list = str(datetime.timedelta(seconds=sec)).split(\".\")\n",
    "    #print(f'SNGnumpy : {result_list[0]}')                 \n",
    "    return np.array(sList).reshape(fIn.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d7beee8-de42-4c97-9189-593d9c0482d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SNGpnumpy(fIn,lfsr):\n",
    "    start = time.time()\n",
    "    sList = []\n",
    "    for aNumpy in fIn.view(-1):\n",
    "        sList.append(SNG_P(float(aNumpy),lfsr))\n",
    "    end = time.time()\n",
    "    sec = (end-start)\n",
    "    result_list = str(datetime.timedelta(seconds=sec)).split(\".\")\n",
    "    #print(f'SNGpnumpy : {result_list[0]}')                   \n",
    "    return  np.array(sList).reshape(fIn.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f10933a-5546-4177-8d73-2ea29cdd2c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CountOne(nIn):\n",
    "    nlist = []\n",
    "    for num in nIn.reshape(-1):\n",
    "        n = 0\n",
    "        for a in num:\n",
    "            if a == '1' :\n",
    "                n += 1\n",
    "        if a[0] == '1' :\n",
    "            nlist.append(n-1)\n",
    "        else :\n",
    "            nlist.append(n)\n",
    "    return torch.tensor(nlist).view(nIn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a260ad6-c49d-49c7-9f1c-23a2022a6c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def defSign(nIn):\n",
    "    nlist = []\n",
    "    for num in nIn.reshape(-1):\n",
    "        if num[0] == '1' :\n",
    "            nlist.append(-1)\n",
    "        else :\n",
    "            nlist.append(1)\n",
    "    return torch.tensor(nlist).view(nIn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e13f3a9d-28f2-4318-b559-b69ccc41dff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mul(a,b):\n",
    "    al = len(a)\n",
    "    bl = len(b)\n",
    "    \n",
    "    outlist = []\n",
    "    \n",
    "    if al != bl :\n",
    "        print(\"length of string is different\")\n",
    "        return 0\n",
    "    \n",
    "    outlist.append(XOR(a[0],b[0]))\n",
    "    \n",
    "    for i in range(al-1) :\n",
    "        outlist.append(str(int(a[i+1]) & int(b[i+1])))\n",
    "    \n",
    "    #print(outlist)\n",
    "    out = \"\".join(outlist)\n",
    "    \n",
    "    return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94b07d95-1b58-4f20-b2c2-9d10c4f43367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def defSign1(nIn):\n",
    "    if nIn[0] == '1' :\n",
    "        return -1\n",
    "    else :\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77dbf36f-2b4b-4282-843b-cc7b783e2bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CountOne1(nIn):\n",
    "    n = 0\n",
    "    for num in nIn:\n",
    "        if num == '1' :\n",
    "            n += 1\n",
    "    if nIn[0] == '1' :\n",
    "        return n-1\n",
    "    else :\n",
    "        return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a82f5cb-dc51-4d3b-bd35-ac7f434ca42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def S2None(sIn,SF):\n",
    "    s = defSign1(sIn)\n",
    "    o = (CountOne1(sIn)/(2**args.bBW))*SF*s\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c1daf7e-01c3-4b01-886a-7dbb7260237e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mulNumpy(aIn,bIn,aSF,wSF):\n",
    "    start = time.time()\n",
    "    mList = []\n",
    "    for i in range(aIn.shape[0]):\n",
    "        for j in range(bIn.T.shape[1]):\n",
    "            sum = 0\n",
    "            for k in range(aIn.shape[1]):\n",
    "                sum += S2None(mul((aIn[i][k].astype(str)),(bIn.T)[k][j].astype(str)),aSF*wSF)\n",
    "            mList.append(sum)\n",
    "    end = time.time()\n",
    "    sec = (end-start)\n",
    "    result_list = str(datetime.timedelta(seconds=sec)).split(\".\")\n",
    "    #print(f'mulNumpy : {result_list[0]}')\n",
    "    return torch.tensor(mList).view(aIn.shape[0],bIn.T.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a64f100-1744-4e06-a386-a6059781e6f4",
   "metadata": {},
   "source": [
    "## Find max, min "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d38c9f7f-f3ab-4d1b-95db-941091645fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMaxMin(data):\n",
    "    start = time.time()\n",
    "    \n",
    "    max = torch.max(data)\n",
    "    min = torch.min(data)\n",
    "    SF=torch.max(abs(max),abs(min)).item()\n",
    "    \n",
    "    end = time.time()\n",
    "    sec = (end-start)\n",
    "    result_list = str(datetime.timedelta(seconds=sec)).split(\".\")\n",
    "    #print(f'findMaxMin : {result_list[0]}')\n",
    "    \n",
    "    return SF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1828b2-ac9c-463b-a05c-c2945674eecd",
   "metadata": {},
   "source": [
    "## Fixed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d113cc44-8936-42f4-9edc-d5a9500c3ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2fix(model, args):\n",
    "\tfor name, _ in model.named_parameters():\n",
    "\t\texec(f'model.{name}.data = flp2fixTensor(model.{name}.data, {args.full_bits}, {args.frac_bits})')\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7d60934-4e57-4e85-9737-a4e81a7f56da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def N2S2N(model, iX, iW, iB, args):\n",
    "    lfsr = LFSRlist7()\n",
    "    \n",
    "    xSF = findMaxMin(iX)\n",
    "    wSF = findMaxMin(iW)\n",
    "    \n",
    "    x = SNGnumpy(iX/xSF,lfsr)\n",
    "    w = SNGpnumpy(iW/wSF,lfsr)\n",
    "    \n",
    "    sout = mulNumpy(x,w,xSF,wSF) + iB\n",
    "    \n",
    "    return sout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "450e4437-1f3c-4976-bf36-f66da4b8fd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantFixForward(model, x, args):\n",
    "    cmodel = copy.deepcopy(model).to(args.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        i0 = cmodel.flatten(x)\n",
    "        act0 = N2S2N(cmodel,i0,cmodel.fc1.weight,cmodel.fc1.bias,args)\n",
    "        #print(\"act0 successed\")\n",
    "        \n",
    "        i1 = model.relu1(act0)\n",
    "        act1 = N2S2N(cmodel,i1,cmodel.fc2.weight,cmodel.fc2.bias,args)\n",
    "        #print(\"act1 successed\")\n",
    "        \n",
    "        i2 = cmodel.relu2(act1)\n",
    "        act2 = N2S2N(cmodel,i2,cmodel.fc3.weight,cmodel.fc3.bias,args)\n",
    "        #print(\"act2 successed\")\n",
    "        \n",
    "        act3 = flp2fixTensor(act2, args.full_bits, args.frac_bits)\n",
    "        #print(\"act3 successed\")\n",
    "    return cmodel, act0, act1, act2, act3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a41e1a82-82ee-42fa-9f7f-8ff0981e3d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testQuant(model, test_loader, args):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    qmodel = copy.deepcopy(model).to(args.device)\n",
    "    qmodel = model2fix(qmodel, args)\n",
    "    qmodel.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loss_func = genLossFunc(args)\n",
    "        loss, correct = 0, 0\n",
    "        for batch_index, (image, label) in enumerate(tq(test_loader,desc='Test',leave=False)):\n",
    "            start = time.time()\n",
    "            image, label = image.to(args.device), label.to(args.device)\n",
    "            qmodel, act0, act1, act2, act3  = quantFixForward(qmodel, image, args)\n",
    "            y = act3\n",
    "            loss += loss_func(y, label).item()#*image.size(0)\n",
    "            correct += (y.argmax(1) == label).type(torch.int).sum().item()\n",
    "            end = time.time()\n",
    "            sec = end - start\n",
    "            result_list = str(datetime.timedelta(seconds=sec)).split(\".\")\n",
    "            print(f'image {batch_index} time  : {result_list[0]}')\n",
    "    correct_rate = 100 * correct / len(test_loader.dataset)\n",
    "    print(f'Accuracy: {correct}/{len(test_loader.dataset)} ({correct_rate:>.1f}%) Loss: {loss/len(test_loader.dataset):.2f}')\n",
    "    \n",
    "    end = time.time()\n",
    "    sec = (end-start)\n",
    "    result_list = str(datetime.timedelta(seconds=sec)).split(\".\")\n",
    "    print(f'Total time is : {result_list[0]}')\n",
    "    return qmodel, act0, act1, act2, act3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "824c658d-8ac0-41cf-afec-21c721f67ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 0 time  : 0:01:52\n",
      "image 1 time  : 0:01:53\n",
      "image 2 time  : 0:01:51\n",
      "image 3 time  : 0:01:52\n",
      "image 4 time  : 0:01:52\n",
      "image 5 time  : 0:01:52\n",
      "image 6 time  : 0:01:52\n",
      "image 7 time  : 0:01:52\n",
      "image 8 time  : 0:01:52\n",
      "image 9 time  : 0:01:51\n",
      "image 10 time  : 0:01:53\n",
      "image 11 time  : 0:01:52\n",
      "image 12 time  : 0:01:52\n",
      "image 13 time  : 0:01:51\n",
      "image 14 time  : 0:01:52\n",
      "image 15 time  : 0:01:52\n",
      "image 16 time  : 0:01:52\n",
      "image 17 time  : 0:01:52\n",
      "image 18 time  : 0:01:53\n",
      "image 19 time  : 0:01:52\n",
      "image 20 time  : 0:01:52\n",
      "image 21 time  : 0:01:52\n",
      "image 22 time  : 0:01:53\n",
      "image 23 time  : 0:01:53\n",
      "image 24 time  : 0:01:53\n",
      "image 25 time  : 0:01:52\n",
      "image 26 time  : 0:01:52\n",
      "image 27 time  : 0:01:53\n",
      "image 28 time  : 0:01:52\n",
      "image 29 time  : 0:01:52\n",
      "image 30 time  : 0:01:52\n",
      "image 31 time  : 0:01:53\n",
      "image 32 time  : 0:01:52\n",
      "image 33 time  : 0:01:53\n",
      "image 34 time  : 0:01:52\n",
      "image 35 time  : 0:01:53\n",
      "1b10111011111111\n",
      "1b11101011000011\n",
      "10b1001001110110\n",
      "1b10001101010010\n",
      "1000b10101111110\n",
      "100b111010010010\n",
      "100b110000010010\n",
      "10b1111000111010\n",
      "1b11100000010011\n",
      "1b11111010001111\n",
      "1b10000011000100\n",
      "10b1101110101010\n",
      "10b1111000100010\n",
      "1b11111010100111\n",
      "10b1110011101110\n",
      "1b11111111011011\n",
      "100000b110011010\n",
      "1b11010001000111\n",
      "10b1011001011010\n",
      "10b1001001110110\n",
      "1b10110001111111\n",
      "1b11000110010111\n",
      "10000000b1101110\n",
      "100b101111111010\n",
      "10b1100011111100\n",
      "1b10000011010010\n",
      "100b100000110110\n",
      "100b100101100010\n",
      "1b10101100110011\n",
      "1b11000001001011\n",
      "1000b10001010010\n",
      "1b11101111110111\n",
      "1000b11011101010\n",
      "1000b10101111110\n",
      "10b1100100001010\n",
      "1b11110000010111\n",
      "10b1000000000011\n",
      "100b110000011111\n",
      "1b11100000101011\n",
      "10b1001010001110\n",
      "100000b110110010\n",
      "1b11100101011111\n",
      "100b111010101010\n",
      "1b11000110101111\n",
      "1b10101100011011\n",
      "10b1011110110000\n",
      "10b1110011101110\n",
      "1000b10000110010\n",
      "100b100000101110\n",
      "image 36 time  : 0:01:52\n",
      "image 37 time  : 0:01:52\n",
      "image 38 time  : 0:01:53\n",
      "image 39 time  : 0:01:52\n",
      "image 40 time  : 0:01:53\n",
      "image 41 time  : 0:01:53\n",
      "image 42 time  : 0:01:52\n",
      "image 43 time  : 0:01:52\n",
      "image 44 time  : 0:01:52\n",
      "image 45 time  : 0:01:52\n",
      "image 46 time  : 0:01:52\n",
      "image 47 time  : 0:01:53\n",
      "image 48 time  : 0:01:52\n",
      "image 49 time  : 0:01:52\n",
      "image 50 time  : 0:01:52\n",
      "image 51 time  : 0:01:53\n",
      "image 52 time  : 0:01:52\n",
      "image 53 time  : 0:01:52\n",
      "image 54 time  : 0:01:53\n",
      "image 55 time  : 0:01:52\n",
      "image 56 time  : 0:01:53\n",
      "image 57 time  : 0:01:52\n",
      "image 58 time  : 0:01:53\n",
      "image 59 time  : 0:01:52\n",
      "image 60 time  : 0:01:52\n",
      "image 61 time  : 0:01:52\n",
      "image 62 time  : 0:01:53\n",
      "image 63 time  : 0:01:52\n",
      "image 64 time  : 0:01:52\n",
      "image 65 time  : 0:01:52\n",
      "image 66 time  : 0:01:53\n",
      "image 67 time  : 0:01:52\n",
      "image 68 time  : 0:01:52\n",
      "image 69 time  : 0:01:52\n",
      "image 70 time  : 0:01:52\n",
      "image 71 time  : 0:01:53\n",
      "image 72 time  : 0:01:52\n",
      "image 73 time  : 0:01:52\n",
      "image 74 time  : 0:01:52\n",
      "image 75 time  : 0:01:52\n",
      "image 76 time  : 0:01:52\n",
      "image 77 time  : 0:01:52\n",
      "image 78 time  : 0:01:53\n",
      "image 79 time  : 0:01:52\n",
      "image 80 time  : 0:01:52\n",
      "image 81 time  : 0:01:52\n",
      "image 82 time  : 0:01:52\n",
      "image 83 time  : 0:01:49\n",
      "image 84 time  : 0:01:49\n",
      "image 85 time  : 0:01:50\n",
      "image 86 time  : 0:01:50\n",
      "image 87 time  : 0:01:49\n",
      "image 88 time  : 0:01:49\n",
      "image 89 time  : 0:01:49\n",
      "image 90 time  : 0:01:50\n",
      "image 91 time  : 0:01:49\n",
      "image 92 time  : 0:01:49\n",
      "image 93 time  : 0:01:50\n",
      "image 94 time  : 0:01:50\n",
      "image 95 time  : 0:01:49\n",
      "image 96 time  : 0:01:49\n",
      "image 97 time  : 0:01:49\n",
      "image 98 time  : 0:01:49\n",
      "image 99 time  : 0:01:49\n",
      "image 100 time  : 0:01:49\n",
      "image 101 time  : 0:01:49\n",
      "image 102 time  : 0:01:49\n",
      "image 103 time  : 0:01:49\n",
      "image 104 time  : 0:01:50\n",
      "image 105 time  : 0:01:49\n",
      "image 106 time  : 0:01:49\n",
      "image 107 time  : 0:01:49\n",
      "image 108 time  : 0:01:49\n",
      "image 109 time  : 0:01:49\n",
      "image 110 time  : 0:01:49\n",
      "image 111 time  : 0:01:49\n",
      "image 112 time  : 0:01:50\n",
      "image 113 time  : 0:01:49\n",
      "image 114 time  : 0:01:48\n",
      "image 115 time  : 0:01:48\n",
      "image 116 time  : 0:01:49\n",
      "image 117 time  : 0:01:49\n",
      "image 118 time  : 0:01:49\n",
      "image 119 time  : 0:01:50\n",
      "image 120 time  : 0:01:49\n",
      "image 121 time  : 0:01:49\n",
      "image 122 time  : 0:01:48\n",
      "image 123 time  : 0:01:48\n",
      "image 124 time  : 0:01:49\n",
      "image 125 time  : 0:01:49\n",
      "image 126 time  : 0:01:49\n",
      "image 127 time  : 0:01:49\n",
      "image 128 time  : 0:01:49\n",
      "image 129 time  : 0:01:49\n",
      "image 130 time  : 0:01:48\n",
      "image 131 time  : 0:01:48\n",
      "image 132 time  : 0:01:49\n",
      "image 133 time  : 0:01:49\n",
      "image 134 time  : 0:01:49\n",
      "image 135 time  : 0:01:50\n",
      "image 136 time  : 0:01:49\n",
      "image 137 time  : 0:01:49\n",
      "image 138 time  : 0:01:49\n",
      "image 139 time  : 0:01:49\n",
      "image 140 time  : 0:01:49\n",
      "image 141 time  : 0:01:49\n",
      "image 142 time  : 0:01:49\n",
      "image 143 time  : 0:01:49\n",
      "image 144 time  : 0:01:49\n",
      "image 145 time  : 0:01:50\n",
      "image 146 time  : 0:01:49\n",
      "image 147 time  : 0:01:49\n",
      "image 148 time  : 0:01:49\n",
      "1b11001000011001\n",
      "1b11010000001110\n",
      "1b11101011100111\n",
      "10b1111011011100\n",
      "1b11110110100101\n",
      "1b10001001001001\n",
      "1b11110001011111\n",
      "10b1100011000000\n",
      "1b11011101111011\n",
      "1b11011110000101\n",
      "1b10001110100111\n",
      "10b1101101111110\n",
      "1b10110111100100\n",
      "1b11001010111001\n",
      "1b10010100010101\n",
      "1b10100100011000\n",
      "1b11011110000101\n",
      "1b11101110110000\n",
      "1b10101111100000\n",
      "10b1101101111110\n",
      "100b100011100110\n",
      "1b10001011111000\n",
      "10b1110000101101\n",
      "1b11001000100110\n",
      "1000b10000011011\n",
      "1b11001011010100\n",
      "10b1000111011000\n",
      "1b10100010001111\n",
      "1b10001011101110\n",
      "10b1010101000101\n",
      "1b10010100010101\n",
      "1b10101100100110\n",
      "10b1100011000000\n",
      "1b11011101111011\n",
      "1b10100010000010\n",
      "1b10011110111001\n",
      "1b11011110000101\n",
      "1b11101000111000\n",
      "1b11000010101011\n",
      "1b11010000100111\n",
      "1b10101111010110\n",
      "1b10101111100000\n",
      "1b10111101011011\n",
      "1b10011111000011\n",
      "10b1111011011100\n",
      "1b10011100100011\n",
      "100b111001111010\n",
      "1b10011110111001\n",
      "1b10111010011101\n",
      "1b11001011001000\n",
      "1b10001000111111\n",
      "1b10011001100101\n",
      "10b1001111110101\n",
      "10b1011010011001\n",
      "1b10011100010100\n",
      "10b1000100111000\n",
      "1b11011011110001\n",
      "1b11100110001001\n",
      "10b1101000010000\n",
      "10b1110000101101\n",
      "1b10101010011101\n",
      "1b11101000111000\n",
      "1b10011001100101\n",
      "10b1101000011111\n",
      "1b10111111110010\n",
      "1b11011110000101\n",
      "1b11100011110010\n",
      "1b11110110100101\n",
      "10b1110101111101\n",
      "10b1011010110010\n",
      "100b111001101011\n",
      "10000b1000100110\n",
      "1b11011011110001\n",
      "100b110100000010\n",
      "1b10010110110101\n",
      "10000b1011010101\n",
      "1000b11011011000\n",
      "10b1000111011000\n",
      "10b1011101100010\n",
      "1b10111101101000\n",
      "1b11101011100111\n",
      "1b11011011010101\n",
      "1b10110101001101\n",
      "1b11000010100001\n",
      "1000000000b11000\n",
      "1b10111010010011\n",
      "10000b1011010101\n",
      "1b11001011010101\n",
      "1b10001110011101\n",
      "100b110001011101\n",
      "10b1001101000110\n",
      "1b11101110010111\n",
      "1b11100011100011\n",
      "1b10111010011101\n",
      "1b11010000100111\n",
      "1b10000011100000\n",
      "1b10011100010100\n",
      "10b1100000010001\n",
      "1b10111111110010\n",
      "10b1101011000000\n",
      "1b10111010101100\n",
      "1b11110110101111\n",
      "10b1010010100100\n",
      "1b10010011111100\n",
      "100b111100011010\n",
      "1b10001110110110\n",
      "10b1101101100101\n",
      "1000000b10111000\n",
      "10000b1000100110\n",
      "1b10100100111110\n",
      "10b1010111101010\n",
      "1000b10110000011\n",
      "10b1110000111010\n",
      "100b100011100110\n",
      "10b1101011000000\n",
      "100b111100101001\n",
      "10b1000111110100\n",
      "100b101001000101\n",
      "1b10001110100111\n",
      "1b10000001001001\n",
      "10b1000001101111\n",
      "1b10100100100010\n",
      "100b110111001011\n",
      "1b11111111011001\n",
      "1b10010001001101\n",
      "1b10001001001001\n",
      "10b1110000101101\n",
      "1000b10101111001\n",
      "1b10101111100000\n",
      "1b10001100000111\n",
      "10b1010111101010\n",
      "10b1001010000111\n",
      "10000b1011010101\n",
      "100b110100101000\n",
      "1b11100110010011\n",
      "100b111100101001\n",
      "1b11010000001110\n",
      "10b1010111110100\n",
      "10b1111011101011\n",
      "1b11010000011000\n",
      "1b11000010111010\n",
      "1b11101000111000\n",
      "1000b10011010100\n",
      "1000b11110001000\n",
      "10b1000111011000\n",
      "100b101110111101\n",
      "1b10101010011101\n",
      "1b10111010111001\n",
      "1b10000110001111\n",
      "1b10000011111001\n",
      "10b1110011000100\n",
      "10b1100000010001\n",
      "1b10110111100100\n",
      "1b10010100010101\n",
      "1b10100100011000\n",
      "10b1110011101010\n",
      "1b11011011001011\n",
      "1b10111111111100\n",
      "1b10001000111111\n",
      "1000b10000100101\n",
      "1b10101111111100\n",
      "1000000b10101110\n",
      "10b1011111111000\n",
      "10b1010010010101\n",
      "1b10111101011011\n",
      "1b11101110010111\n",
      "image 149 time  : 0:01:49\n",
      "image 150 time  : 0:01:48\n",
      "image 151 time  : 0:01:49\n",
      "image 152 time  : 0:01:48\n",
      "image 153 time  : 0:01:49\n",
      "image 154 time  : 0:01:48\n",
      "image 155 time  : 0:01:48\n",
      "image 156 time  : 0:00:31\n",
      "Accuracy: 9049/10000 (90.5%) Loss: 0.02\n",
      "Total time is : 0:00:31\n"
     ]
    }
   ],
   "source": [
    "qmodel, act0, act1, act2, act3 = testQuant(model, test_loader, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d87a65-ff94-4f6b-9ad2-9608970f0ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
